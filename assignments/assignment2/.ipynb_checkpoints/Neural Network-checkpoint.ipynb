{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_out\n",
      "Gradient check passed!\n",
      "Checking gradient for W_in\n",
      "Gradient check passed!\n",
      "Checking gradient for B_out\n",
      "Gradient check passed!\n",
      "Checking gradient for B_in\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W_out\n",
      "Gradient check passed!\n",
      "Checking gradient for W_in\n",
      "Gradient check passed!\n",
      "Checking gradient for B_out\n",
      "Gradient check passed!\n",
      "Checking gradient for B_in\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303189, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302824, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301440, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302104, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301657, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303184, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302378, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301976, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302000, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302072, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302073, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302983, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302435, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302093, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302467, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b39caabc8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b3bfb5808>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.235902, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209755, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284733, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253025, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221107, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274591, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294909, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251396, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.354615, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272130, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226715, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279512, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263794, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225826, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258595, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258881, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.139735, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.355168, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.320490, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308908, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285667, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281102, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305996, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296499, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262741, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319219, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271805, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239979, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302256, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272388, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284094, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275231, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260643, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291107, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304130, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231559, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b4aedbe88>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351386, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319573, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.320329, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.281196, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.331344, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.253567, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.277398, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.208324, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.227107, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.030399, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.122037, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.873827, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.921337, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.775937, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.085005, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.817975, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.106093, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.368405, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.121562, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.584942, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.947412, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.726571, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.755935, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.838188, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.228244, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.111308, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.721648, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.141381, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.780013, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.931743, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.818621, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.506972, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.878513, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.240420, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.671532, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.845841, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.834279, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.885771, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.074952, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.370104, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.781072, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.625678, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.660183, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.643286, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.394114, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.363041, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.179197, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.358390, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.700854, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 0.820708, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.347979, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.072846, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.454723, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.457327, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.650330, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.250412, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.266090, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.754367, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.264470, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.286876, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.983230, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.625142, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.743834, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.798522, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.195205, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.370609, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.355454, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.339356, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.902429, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.007827, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.248346, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.020295, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.227555, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.583440, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.418328, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.976943, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.345475, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.594437, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.137630, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.308410, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.031786, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.976830, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.390303, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.050395, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.310691, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.291077, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.373447, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.941530, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.323198, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.665275, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.142289, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.566841, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.574824, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.260416, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.204598, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.411905, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.288506, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.310923, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.263796, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.295994, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.217932, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.566314, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.964486, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.273538, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.903287, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.255306, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.537363, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.532080, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.179853, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.317676, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.240337, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.404147, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.611186, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.149537, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.274862, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.099579, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.087049, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.599867, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.228474, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.152394, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.456976, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.411732, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.691240, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.442164, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.419263, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.398199, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.127397, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.402695, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.368445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.415614, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.284091, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.669777, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.128049, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.142164, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.216886, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.333346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449104, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.430849, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.343800, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.463846, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.292512, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.389042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.582065, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.435610, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.253898, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.222749, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.362537, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.275578, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.130505, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.434080, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.304306, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.275987, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.295590, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.267127, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.061310, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: 1.771265, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 1.218701, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.171992, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.448017, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.263868, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.576154, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.486987, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.628227, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.479407, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.365958, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.084384, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.005603, Train accuracy: 0.933333, val accuracy: 0.133333\n",
      "Loss: 0.283396, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.027950, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.222326, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 300, reg = 1e-5)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=10)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.067986, Train accuracy: 0.337333, val accuracy: 0.344000\n",
      "Loss: 1.431737, Train accuracy: 0.527333, val accuracy: 0.514000\n",
      "Loss: 1.655243, Train accuracy: 0.573778, val accuracy: 0.553000\n",
      "Loss: 1.362651, Train accuracy: 0.567556, val accuracy: 0.557000\n",
      "Loss: 1.916997, Train accuracy: 0.587111, val accuracy: 0.564000\n",
      "Loss: 1.627192, Train accuracy: 0.645000, val accuracy: 0.603000\n",
      "Loss: 1.623209, Train accuracy: 0.606333, val accuracy: 0.594000\n",
      "Loss: 1.650115, Train accuracy: 0.600444, val accuracy: 0.585000\n",
      "Loss: 1.581066, Train accuracy: 0.659444, val accuracy: 0.628000\n",
      "Loss: 1.425112, Train accuracy: 0.645111, val accuracy: 0.618000\n",
      "Loss: 1.363623, Train accuracy: 0.668111, val accuracy: 0.652000\n",
      "Loss: 1.905670, Train accuracy: 0.585667, val accuracy: 0.581000\n",
      "Loss: 1.749270, Train accuracy: 0.649333, val accuracy: 0.636000\n",
      "Loss: 1.682766, Train accuracy: 0.629111, val accuracy: 0.599000\n",
      "Loss: 1.868938, Train accuracy: 0.670778, val accuracy: 0.621000\n",
      "Loss: 1.380007, Train accuracy: 0.643111, val accuracy: 0.634000\n",
      "Loss: 1.573604, Train accuracy: 0.617000, val accuracy: 0.612000\n",
      "Loss: 1.510804, Train accuracy: 0.665333, val accuracy: 0.636000\n",
      "Loss: 1.404125, Train accuracy: 0.689778, val accuracy: 0.649000\n",
      "Loss: 1.363516, Train accuracy: 0.641778, val accuracy: 0.609000\n",
      "Loss: 2.222614, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.872073, Train accuracy: 0.415000, val accuracy: 0.412000\n",
      "Loss: 1.554863, Train accuracy: 0.508889, val accuracy: 0.501000\n",
      "Loss: 1.113110, Train accuracy: 0.623667, val accuracy: 0.613000\n",
      "Loss: 1.253152, Train accuracy: 0.652333, val accuracy: 0.650000\n",
      "Loss: 1.446957, Train accuracy: 0.682222, val accuracy: 0.652000\n",
      "Loss: 1.319290, Train accuracy: 0.677000, val accuracy: 0.644000\n",
      "Loss: 1.394700, Train accuracy: 0.681778, val accuracy: 0.640000\n",
      "Loss: 1.000452, Train accuracy: 0.667667, val accuracy: 0.646000\n",
      "Loss: 1.254679, Train accuracy: 0.707333, val accuracy: 0.682000\n",
      "Loss: 1.373739, Train accuracy: 0.703222, val accuracy: 0.676000\n",
      "Loss: 1.103196, Train accuracy: 0.722667, val accuracy: 0.671000\n",
      "Loss: 1.314211, Train accuracy: 0.697778, val accuracy: 0.668000\n",
      "Loss: 1.433040, Train accuracy: 0.715889, val accuracy: 0.669000\n",
      "Loss: 1.182305, Train accuracy: 0.741333, val accuracy: 0.692000\n",
      "Loss: 1.072842, Train accuracy: 0.719222, val accuracy: 0.665000\n",
      "Loss: 1.005502, Train accuracy: 0.747000, val accuracy: 0.703000\n",
      "Loss: 0.839442, Train accuracy: 0.719000, val accuracy: 0.666000\n",
      "Loss: 1.314429, Train accuracy: 0.745667, val accuracy: 0.693000\n",
      "Loss: 1.168434, Train accuracy: 0.748333, val accuracy: 0.705000\n",
      "Loss: 1.859040, Train accuracy: 0.358889, val accuracy: 0.368000\n",
      "Loss: 1.695926, Train accuracy: 0.522444, val accuracy: 0.534000\n",
      "Loss: 1.310627, Train accuracy: 0.526556, val accuracy: 0.511000\n",
      "Loss: 1.680424, Train accuracy: 0.580333, val accuracy: 0.559000\n",
      "Loss: 1.791062, Train accuracy: 0.582556, val accuracy: 0.577000\n",
      "Loss: 1.502949, Train accuracy: 0.605556, val accuracy: 0.593000\n",
      "Loss: 1.462593, Train accuracy: 0.648778, val accuracy: 0.607000\n",
      "Loss: 1.786719, Train accuracy: 0.549000, val accuracy: 0.515000\n",
      "Loss: 2.288380, Train accuracy: 0.623222, val accuracy: 0.592000\n",
      "Loss: 1.675140, Train accuracy: 0.650111, val accuracy: 0.630000\n",
      "Loss: 2.065862, Train accuracy: 0.609000, val accuracy: 0.595000\n",
      "Loss: 1.949476, Train accuracy: 0.621889, val accuracy: 0.576000\n",
      "Loss: 2.258756, Train accuracy: 0.611222, val accuracy: 0.596000\n",
      "Loss: 1.756677, Train accuracy: 0.651556, val accuracy: 0.620000\n",
      "Loss: 1.911346, Train accuracy: 0.653778, val accuracy: 0.597000\n",
      "Loss: 1.721578, Train accuracy: 0.662444, val accuracy: 0.614000\n",
      "Loss: 2.006992, Train accuracy: 0.663000, val accuracy: 0.627000\n",
      "Loss: 1.603366, Train accuracy: 0.610222, val accuracy: 0.583000\n",
      "Loss: 1.475434, Train accuracy: 0.693111, val accuracy: 0.642000\n",
      "Loss: 2.023541, Train accuracy: 0.559333, val accuracy: 0.551000\n",
      "Loss: 2.171613, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.658344, Train accuracy: 0.412222, val accuracy: 0.432000\n",
      "Loss: 1.526998, Train accuracy: 0.530556, val accuracy: 0.533000\n",
      "Loss: 1.767063, Train accuracy: 0.599111, val accuracy: 0.580000\n",
      "Loss: 1.426911, Train accuracy: 0.630333, val accuracy: 0.603000\n",
      "Loss: 1.044014, Train accuracy: 0.708556, val accuracy: 0.678000\n",
      "Loss: 1.011539, Train accuracy: 0.672222, val accuracy: 0.654000\n",
      "Loss: 1.581576, Train accuracy: 0.689778, val accuracy: 0.646000\n",
      "Loss: 1.401904, Train accuracy: 0.701667, val accuracy: 0.651000\n",
      "Loss: 1.272167, Train accuracy: 0.717556, val accuracy: 0.666000\n",
      "Loss: 1.378064, Train accuracy: 0.719111, val accuracy: 0.657000\n",
      "Loss: 1.155687, Train accuracy: 0.770000, val accuracy: 0.713000\n",
      "Loss: 1.353216, Train accuracy: 0.762111, val accuracy: 0.694000\n",
      "Loss: 1.021428, Train accuracy: 0.754556, val accuracy: 0.690000\n",
      "Loss: 1.689860, Train accuracy: 0.786556, val accuracy: 0.725000\n",
      "Loss: 1.057005, Train accuracy: 0.722667, val accuracy: 0.662000\n",
      "Loss: 1.294060, Train accuracy: 0.754556, val accuracy: 0.698000\n",
      "Loss: 1.287709, Train accuracy: 0.768778, val accuracy: 0.707000\n",
      "Loss: 1.391092, Train accuracy: 0.751000, val accuracy: 0.693000\n",
      "Loss: 1.138318, Train accuracy: 0.734889, val accuracy: 0.687000\n",
      "Loss: 1.728340, Train accuracy: 0.382778, val accuracy: 0.395000\n",
      "Loss: 1.922591, Train accuracy: 0.484333, val accuracy: 0.475000\n",
      "Loss: 1.304800, Train accuracy: 0.621444, val accuracy: 0.588000\n",
      "Loss: 1.850015, Train accuracy: 0.534000, val accuracy: 0.513000\n",
      "Loss: 2.059496, Train accuracy: 0.625333, val accuracy: 0.600000\n",
      "Loss: 1.642931, Train accuracy: 0.640333, val accuracy: 0.616000\n",
      "Loss: 1.514403, Train accuracy: 0.683000, val accuracy: 0.630000\n",
      "Loss: 1.849067, Train accuracy: 0.589000, val accuracy: 0.557000\n",
      "Loss: 2.187457, Train accuracy: 0.632778, val accuracy: 0.591000\n",
      "Loss: 1.629296, Train accuracy: 0.633556, val accuracy: 0.591000\n",
      "Loss: 1.652904, Train accuracy: 0.678889, val accuracy: 0.633000\n",
      "Loss: 1.718522, Train accuracy: 0.630556, val accuracy: 0.585000\n",
      "Loss: 2.179572, Train accuracy: 0.698889, val accuracy: 0.671000\n",
      "Loss: 1.925299, Train accuracy: 0.645333, val accuracy: 0.614000\n",
      "Loss: 1.462199, Train accuracy: 0.683778, val accuracy: 0.644000\n",
      "Loss: 1.402077, Train accuracy: 0.650778, val accuracy: 0.603000\n",
      "Loss: 1.566284, Train accuracy: 0.647222, val accuracy: 0.601000\n",
      "Loss: 1.627867, Train accuracy: 0.659333, val accuracy: 0.604000\n",
      "Loss: 1.571817, Train accuracy: 0.589222, val accuracy: 0.576000\n",
      "Loss: 1.866022, Train accuracy: 0.700333, val accuracy: 0.645000\n",
      "Loss: 2.164550, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.779914, Train accuracy: 0.472333, val accuracy: 0.457000\n",
      "Loss: 1.447303, Train accuracy: 0.560556, val accuracy: 0.543000\n",
      "Loss: 1.608896, Train accuracy: 0.627556, val accuracy: 0.616000\n",
      "Loss: 1.468647, Train accuracy: 0.660000, val accuracy: 0.634000\n",
      "Loss: 1.582172, Train accuracy: 0.652778, val accuracy: 0.615000\n",
      "Loss: 1.449748, Train accuracy: 0.683556, val accuracy: 0.667000\n",
      "Loss: 1.217210, Train accuracy: 0.742000, val accuracy: 0.693000\n",
      "Loss: 0.965567, Train accuracy: 0.742556, val accuracy: 0.680000\n",
      "Loss: 1.188056, Train accuracy: 0.712000, val accuracy: 0.665000\n",
      "Loss: 1.663690, Train accuracy: 0.721222, val accuracy: 0.688000\n",
      "Loss: 0.948337, Train accuracy: 0.751000, val accuracy: 0.694000\n",
      "Loss: 1.759601, Train accuracy: 0.725222, val accuracy: 0.661000\n",
      "Loss: 1.473207, Train accuracy: 0.722778, val accuracy: 0.668000\n",
      "Loss: 1.085977, Train accuracy: 0.771222, val accuracy: 0.695000\n",
      "Loss: 1.262151, Train accuracy: 0.774667, val accuracy: 0.704000\n",
      "Loss: 1.145156, Train accuracy: 0.765667, val accuracy: 0.691000\n",
      "Loss: 0.971587, Train accuracy: 0.778667, val accuracy: 0.697000\n",
      "Loss: 1.134198, Train accuracy: 0.733889, val accuracy: 0.661000\n",
      "Loss: 1.345290, Train accuracy: 0.794333, val accuracy: 0.720000\n",
      "Loss: 1.990929, Train accuracy: 0.324333, val accuracy: 0.310000\n",
      "Loss: 1.971794, Train accuracy: 0.512444, val accuracy: 0.517000\n",
      "Loss: 1.077731, Train accuracy: 0.582556, val accuracy: 0.591000\n",
      "Loss: 1.486943, Train accuracy: 0.637333, val accuracy: 0.613000\n",
      "Loss: 1.258531, Train accuracy: 0.655556, val accuracy: 0.614000\n",
      "Loss: 1.633100, Train accuracy: 0.645667, val accuracy: 0.634000\n",
      "Loss: 1.334270, Train accuracy: 0.665000, val accuracy: 0.623000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.245825, Train accuracy: 0.673000, val accuracy: 0.627000\n",
      "Loss: 1.527629, Train accuracy: 0.649111, val accuracy: 0.612000\n",
      "Loss: 1.043036, Train accuracy: 0.669889, val accuracy: 0.605000\n",
      "Loss: 1.237763, Train accuracy: 0.696444, val accuracy: 0.664000\n",
      "Loss: 0.945308, Train accuracy: 0.730889, val accuracy: 0.654000\n",
      "Loss: 1.631152, Train accuracy: 0.716111, val accuracy: 0.655000\n",
      "Loss: 1.226368, Train accuracy: 0.748222, val accuracy: 0.669000\n",
      "Loss: 0.976124, Train accuracy: 0.723778, val accuracy: 0.662000\n",
      "Loss: 0.745763, Train accuracy: 0.727444, val accuracy: 0.662000\n",
      "Loss: 1.179147, Train accuracy: 0.739556, val accuracy: 0.660000\n",
      "Loss: 1.253654, Train accuracy: 0.730000, val accuracy: 0.655000\n",
      "Loss: 0.731807, Train accuracy: 0.758444, val accuracy: 0.662000\n",
      "Loss: 1.268775, Train accuracy: 0.749222, val accuracy: 0.676000\n",
      "Loss: 2.119293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.709735, Train accuracy: 0.397778, val accuracy: 0.408000\n",
      "Loss: 1.302164, Train accuracy: 0.556111, val accuracy: 0.568000\n",
      "Loss: 1.428960, Train accuracy: 0.610222, val accuracy: 0.604000\n",
      "Loss: 1.184396, Train accuracy: 0.636111, val accuracy: 0.617000\n",
      "Loss: 0.770714, Train accuracy: 0.690889, val accuracy: 0.653000\n",
      "Loss: 1.070620, Train accuracy: 0.682111, val accuracy: 0.651000\n",
      "Loss: 1.375736, Train accuracy: 0.711000, val accuracy: 0.674000\n",
      "Loss: 0.875039, Train accuracy: 0.743667, val accuracy: 0.688000\n",
      "Loss: 1.320035, Train accuracy: 0.732889, val accuracy: 0.680000\n",
      "Loss: 1.117494, Train accuracy: 0.735667, val accuracy: 0.695000\n",
      "Loss: 0.705940, Train accuracy: 0.775222, val accuracy: 0.700000\n",
      "Loss: 0.837554, Train accuracy: 0.768667, val accuracy: 0.703000\n",
      "Loss: 0.997801, Train accuracy: 0.795111, val accuracy: 0.705000\n",
      "Loss: 0.856106, Train accuracy: 0.796222, val accuracy: 0.702000\n",
      "Loss: 0.652338, Train accuracy: 0.766444, val accuracy: 0.691000\n",
      "Loss: 0.681685, Train accuracy: 0.818556, val accuracy: 0.729000\n",
      "Loss: 0.835101, Train accuracy: 0.810667, val accuracy: 0.700000\n",
      "Loss: 0.591061, Train accuracy: 0.826333, val accuracy: 0.727000\n",
      "Loss: 0.881479, Train accuracy: 0.821556, val accuracy: 0.723000\n",
      "Loss: 1.751263, Train accuracy: 0.342667, val accuracy: 0.357000\n",
      "Loss: 1.608819, Train accuracy: 0.574667, val accuracy: 0.565000\n",
      "Loss: 1.031198, Train accuracy: 0.592000, val accuracy: 0.571000\n",
      "Loss: 1.134924, Train accuracy: 0.656222, val accuracy: 0.627000\n",
      "Loss: 0.634912, Train accuracy: 0.650000, val accuracy: 0.614000\n",
      "Loss: 0.657176, Train accuracy: 0.692556, val accuracy: 0.655000\n",
      "Loss: 1.077726, Train accuracy: 0.704111, val accuracy: 0.652000\n",
      "Loss: 1.046495, Train accuracy: 0.698556, val accuracy: 0.638000\n",
      "Loss: 1.093279, Train accuracy: 0.709222, val accuracy: 0.650000\n",
      "Loss: 1.588231, Train accuracy: 0.710000, val accuracy: 0.640000\n",
      "Loss: 1.032883, Train accuracy: 0.734667, val accuracy: 0.661000\n",
      "Loss: 1.551422, Train accuracy: 0.714556, val accuracy: 0.673000\n",
      "Loss: 0.854338, Train accuracy: 0.737222, val accuracy: 0.653000\n",
      "Loss: 1.116590, Train accuracy: 0.735556, val accuracy: 0.689000\n",
      "Loss: 0.940671, Train accuracy: 0.747889, val accuracy: 0.685000\n",
      "Loss: 1.003946, Train accuracy: 0.774222, val accuracy: 0.708000\n",
      "Loss: 1.230126, Train accuracy: 0.774667, val accuracy: 0.680000\n",
      "Loss: 1.822666, Train accuracy: 0.737778, val accuracy: 0.661000\n",
      "Loss: 0.984736, Train accuracy: 0.769778, val accuracy: 0.690000\n",
      "Loss: 1.177533, Train accuracy: 0.783889, val accuracy: 0.691000\n",
      "Loss: 2.095204, Train accuracy: 0.199222, val accuracy: 0.210000\n",
      "Loss: 1.568754, Train accuracy: 0.449444, val accuracy: 0.452000\n",
      "Loss: 1.416594, Train accuracy: 0.549222, val accuracy: 0.551000\n",
      "Loss: 1.316546, Train accuracy: 0.610444, val accuracy: 0.585000\n",
      "Loss: 0.815912, Train accuracy: 0.650111, val accuracy: 0.643000\n",
      "Loss: 0.814319, Train accuracy: 0.688889, val accuracy: 0.659000\n",
      "Loss: 1.136328, Train accuracy: 0.716667, val accuracy: 0.659000\n",
      "Loss: 1.186603, Train accuracy: 0.759111, val accuracy: 0.696000\n",
      "Loss: 1.030609, Train accuracy: 0.729778, val accuracy: 0.664000\n",
      "Loss: 1.056311, Train accuracy: 0.770222, val accuracy: 0.698000\n",
      "Loss: 1.118760, Train accuracy: 0.783111, val accuracy: 0.714000\n",
      "Loss: 0.740884, Train accuracy: 0.757778, val accuracy: 0.671000\n",
      "Loss: 0.839510, Train accuracy: 0.778556, val accuracy: 0.699000\n",
      "Loss: 0.431680, Train accuracy: 0.767333, val accuracy: 0.680000\n",
      "Loss: 0.560759, Train accuracy: 0.800000, val accuracy: 0.706000\n",
      "Loss: 0.824561, Train accuracy: 0.821556, val accuracy: 0.720000\n",
      "Loss: 0.612110, Train accuracy: 0.816333, val accuracy: 0.693000\n",
      "Loss: 0.674159, Train accuracy: 0.798333, val accuracy: 0.699000\n",
      "Loss: 0.605026, Train accuracy: 0.831778, val accuracy: 0.715000\n",
      "Loss: 0.754663, Train accuracy: 0.843333, val accuracy: 0.715000\n",
      "Loss: 1.856267, Train accuracy: 0.371778, val accuracy: 0.365000\n",
      "Loss: 1.851134, Train accuracy: 0.521667, val accuracy: 0.498000\n",
      "Loss: 1.484667, Train accuracy: 0.583222, val accuracy: 0.573000\n",
      "Loss: 1.536751, Train accuracy: 0.609667, val accuracy: 0.610000\n",
      "Loss: 0.908543, Train accuracy: 0.645000, val accuracy: 0.619000\n",
      "Loss: 1.352281, Train accuracy: 0.652333, val accuracy: 0.606000\n",
      "Loss: 1.379194, Train accuracy: 0.697111, val accuracy: 0.648000\n",
      "Loss: 0.692780, Train accuracy: 0.724889, val accuracy: 0.670000\n",
      "Loss: 1.244812, Train accuracy: 0.692444, val accuracy: 0.621000\n",
      "Loss: 1.121056, Train accuracy: 0.710111, val accuracy: 0.638000\n",
      "Loss: 1.169953, Train accuracy: 0.752889, val accuracy: 0.680000\n",
      "Loss: 1.326972, Train accuracy: 0.710778, val accuracy: 0.642000\n",
      "Loss: 0.985227, Train accuracy: 0.716333, val accuracy: 0.635000\n",
      "Loss: 1.371068, Train accuracy: 0.741333, val accuracy: 0.665000\n",
      "Loss: 1.083099, Train accuracy: 0.783556, val accuracy: 0.697000\n",
      "Loss: 1.150114, Train accuracy: 0.754889, val accuracy: 0.685000\n",
      "Loss: 2.359278, Train accuracy: 0.763111, val accuracy: 0.646000\n",
      "Loss: 1.421443, Train accuracy: 0.748000, val accuracy: 0.657000\n",
      "Loss: 0.781522, Train accuracy: 0.772889, val accuracy: 0.670000\n",
      "Loss: 0.602199, Train accuracy: 0.756333, val accuracy: 0.665000\n",
      "Loss: 2.249135, Train accuracy: 0.209667, val accuracy: 0.219000\n",
      "Loss: 1.566293, Train accuracy: 0.464222, val accuracy: 0.462000\n",
      "Loss: 1.275004, Train accuracy: 0.594556, val accuracy: 0.587000\n",
      "Loss: 1.008643, Train accuracy: 0.644000, val accuracy: 0.618000\n",
      "Loss: 0.737413, Train accuracy: 0.686111, val accuracy: 0.651000\n",
      "Loss: 1.149842, Train accuracy: 0.704778, val accuracy: 0.682000\n",
      "Loss: 1.012951, Train accuracy: 0.676889, val accuracy: 0.626000\n",
      "Loss: 0.644593, Train accuracy: 0.747444, val accuracy: 0.695000\n",
      "Loss: 0.466869, Train accuracy: 0.744111, val accuracy: 0.687000\n",
      "Loss: 0.884483, Train accuracy: 0.739222, val accuracy: 0.679000\n",
      "Loss: 0.861039, Train accuracy: 0.750444, val accuracy: 0.676000\n",
      "Loss: 0.795007, Train accuracy: 0.771000, val accuracy: 0.703000\n",
      "Loss: 0.799305, Train accuracy: 0.809222, val accuracy: 0.714000\n",
      "Loss: 1.022303, Train accuracy: 0.825444, val accuracy: 0.720000\n",
      "Loss: 0.486709, Train accuracy: 0.803889, val accuracy: 0.705000\n",
      "Loss: 0.460021, Train accuracy: 0.834889, val accuracy: 0.744000\n",
      "Loss: 0.876107, Train accuracy: 0.852667, val accuracy: 0.733000\n",
      "Loss: 0.773378, Train accuracy: 0.788000, val accuracy: 0.695000\n",
      "Loss: 0.321878, Train accuracy: 0.840333, val accuracy: 0.720000\n",
      "Loss: 0.588935, Train accuracy: 0.830444, val accuracy: 0.723000\n",
      "Loss: 2.000906, Train accuracy: 0.310667, val accuracy: 0.319000\n",
      "Loss: 2.152965, Train accuracy: 0.531556, val accuracy: 0.513000\n",
      "Loss: 2.258209, Train accuracy: 0.587111, val accuracy: 0.551000\n",
      "Loss: 1.060057, Train accuracy: 0.593889, val accuracy: 0.584000\n",
      "Loss: 0.919072, Train accuracy: 0.652111, val accuracy: 0.629000\n",
      "Loss: 1.054564, Train accuracy: 0.667667, val accuracy: 0.633000\n",
      "Loss: 1.271275, Train accuracy: 0.683000, val accuracy: 0.645000\n",
      "Loss: 1.157493, Train accuracy: 0.677889, val accuracy: 0.640000\n",
      "Loss: 0.805551, Train accuracy: 0.676889, val accuracy: 0.632000\n",
      "Loss: 1.337888, Train accuracy: 0.715556, val accuracy: 0.650000\n",
      "Loss: 1.429669, Train accuracy: 0.730556, val accuracy: 0.666000\n",
      "Loss: 1.096995, Train accuracy: 0.760778, val accuracy: 0.697000\n",
      "Loss: 1.037418, Train accuracy: 0.734778, val accuracy: 0.646000\n",
      "Loss: 0.738822, Train accuracy: 0.719444, val accuracy: 0.651000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.756574, Train accuracy: 0.751889, val accuracy: 0.684000\n",
      "Loss: 0.778444, Train accuracy: 0.754333, val accuracy: 0.675000\n",
      "Loss: 0.836739, Train accuracy: 0.755333, val accuracy: 0.680000\n",
      "Loss: 0.689803, Train accuracy: 0.786111, val accuracy: 0.684000\n",
      "Loss: 1.000335, Train accuracy: 0.750000, val accuracy: 0.668000\n",
      "Loss: 1.044970, Train accuracy: 0.801667, val accuracy: 0.706000\n",
      "Loss: 2.247193, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.681153, Train accuracy: 0.383778, val accuracy: 0.371000\n",
      "Loss: 1.613245, Train accuracy: 0.524333, val accuracy: 0.522000\n",
      "Loss: 1.285920, Train accuracy: 0.652778, val accuracy: 0.624000\n",
      "Loss: 1.443352, Train accuracy: 0.631889, val accuracy: 0.618000\n",
      "Loss: 1.375593, Train accuracy: 0.670111, val accuracy: 0.652000\n",
      "Loss: 0.784063, Train accuracy: 0.691222, val accuracy: 0.651000\n",
      "Loss: 0.855900, Train accuracy: 0.717889, val accuracy: 0.694000\n",
      "Loss: 0.823519, Train accuracy: 0.707556, val accuracy: 0.653000\n",
      "Loss: 0.564603, Train accuracy: 0.756667, val accuracy: 0.698000\n",
      "Loss: 0.820066, Train accuracy: 0.771444, val accuracy: 0.710000\n",
      "Loss: 0.725200, Train accuracy: 0.760556, val accuracy: 0.694000\n",
      "Loss: 0.645558, Train accuracy: 0.802778, val accuracy: 0.713000\n",
      "Loss: 0.614194, Train accuracy: 0.755222, val accuracy: 0.658000\n",
      "Loss: 0.592683, Train accuracy: 0.781667, val accuracy: 0.683000\n",
      "Loss: 0.630189, Train accuracy: 0.790778, val accuracy: 0.689000\n",
      "Loss: 0.748545, Train accuracy: 0.798333, val accuracy: 0.697000\n",
      "Loss: 1.221689, Train accuracy: 0.804333, val accuracy: 0.703000\n",
      "Loss: 0.475309, Train accuracy: 0.819444, val accuracy: 0.707000\n",
      "Loss: 0.546095, Train accuracy: 0.836667, val accuracy: 0.710000\n",
      "Loss: 1.692441, Train accuracy: 0.374111, val accuracy: 0.404000\n",
      "Loss: 1.185582, Train accuracy: 0.501778, val accuracy: 0.494000\n",
      "Loss: 0.983044, Train accuracy: 0.590889, val accuracy: 0.569000\n",
      "Loss: 1.076575, Train accuracy: 0.637667, val accuracy: 0.614000\n",
      "Loss: 1.551077, Train accuracy: 0.666111, val accuracy: 0.618000\n",
      "Loss: 1.106131, Train accuracy: 0.680444, val accuracy: 0.636000\n",
      "Loss: 1.249555, Train accuracy: 0.680889, val accuracy: 0.628000\n",
      "Loss: 0.763979, Train accuracy: 0.725000, val accuracy: 0.660000\n",
      "Loss: 1.603623, Train accuracy: 0.694778, val accuracy: 0.637000\n",
      "Loss: 1.613703, Train accuracy: 0.715222, val accuracy: 0.665000\n",
      "Loss: 0.733103, Train accuracy: 0.759667, val accuracy: 0.659000\n",
      "Loss: 1.316576, Train accuracy: 0.732111, val accuracy: 0.640000\n",
      "Loss: 1.411814, Train accuracy: 0.729333, val accuracy: 0.626000\n",
      "Loss: 0.526540, Train accuracy: 0.742889, val accuracy: 0.650000\n",
      "Loss: 0.966865, Train accuracy: 0.748444, val accuracy: 0.669000\n",
      "Loss: 1.231024, Train accuracy: 0.753000, val accuracy: 0.664000\n",
      "Loss: 0.943341, Train accuracy: 0.746889, val accuracy: 0.651000\n",
      "Loss: 0.808753, Train accuracy: 0.776556, val accuracy: 0.677000\n",
      "Loss: 0.461928, Train accuracy: 0.792444, val accuracy: 0.679000\n",
      "Loss: 0.765055, Train accuracy: 0.763778, val accuracy: 0.680000\n",
      "Loss: 2.197286, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.605922, Train accuracy: 0.420556, val accuracy: 0.424000\n",
      "Loss: 1.655329, Train accuracy: 0.569889, val accuracy: 0.576000\n",
      "Loss: 1.133988, Train accuracy: 0.649889, val accuracy: 0.642000\n",
      "Loss: 1.386257, Train accuracy: 0.690111, val accuracy: 0.672000\n",
      "Loss: 1.203333, Train accuracy: 0.707333, val accuracy: 0.669000\n",
      "Loss: 0.949924, Train accuracy: 0.736667, val accuracy: 0.694000\n",
      "Loss: 1.188744, Train accuracy: 0.707556, val accuracy: 0.652000\n",
      "Loss: 1.090860, Train accuracy: 0.777889, val accuracy: 0.706000\n",
      "Loss: 0.636158, Train accuracy: 0.751222, val accuracy: 0.677000\n",
      "Loss: 0.894078, Train accuracy: 0.776222, val accuracy: 0.696000\n",
      "Loss: 0.731689, Train accuracy: 0.795111, val accuracy: 0.699000\n",
      "Loss: 0.819023, Train accuracy: 0.809778, val accuracy: 0.720000\n",
      "Loss: 0.660190, Train accuracy: 0.826667, val accuracy: 0.716000\n",
      "Loss: 0.516366, Train accuracy: 0.797111, val accuracy: 0.713000\n",
      "Loss: 0.652525, Train accuracy: 0.822000, val accuracy: 0.705000\n",
      "Loss: 0.346985, Train accuracy: 0.823000, val accuracy: 0.709000\n",
      "Loss: 0.423902, Train accuracy: 0.804222, val accuracy: 0.698000\n",
      "Loss: 0.648184, Train accuracy: 0.838556, val accuracy: 0.710000\n",
      "Loss: 0.571544, Train accuracy: 0.843333, val accuracy: 0.713000\n",
      "Loss: 1.982770, Train accuracy: 0.356889, val accuracy: 0.364000\n",
      "Loss: 1.818138, Train accuracy: 0.481333, val accuracy: 0.475000\n",
      "Loss: 1.559179, Train accuracy: 0.592333, val accuracy: 0.574000\n",
      "Loss: 0.970467, Train accuracy: 0.649667, val accuracy: 0.629000\n",
      "Loss: 1.227497, Train accuracy: 0.690556, val accuracy: 0.654000\n",
      "Loss: 1.257123, Train accuracy: 0.620000, val accuracy: 0.588000\n",
      "Loss: 2.102902, Train accuracy: 0.648667, val accuracy: 0.597000\n",
      "Loss: 1.165471, Train accuracy: 0.722778, val accuracy: 0.669000\n",
      "Loss: 1.072824, Train accuracy: 0.699222, val accuracy: 0.644000\n",
      "Loss: 0.976670, Train accuracy: 0.748222, val accuracy: 0.676000\n",
      "Loss: 1.033589, Train accuracy: 0.704889, val accuracy: 0.632000\n",
      "Loss: 1.016065, Train accuracy: 0.747000, val accuracy: 0.656000\n",
      "Loss: 1.323600, Train accuracy: 0.752333, val accuracy: 0.668000\n",
      "Loss: 0.652925, Train accuracy: 0.760556, val accuracy: 0.656000\n",
      "Loss: 1.329294, Train accuracy: 0.742556, val accuracy: 0.657000\n",
      "Loss: 1.115344, Train accuracy: 0.799222, val accuracy: 0.702000\n",
      "Loss: 1.112988, Train accuracy: 0.780333, val accuracy: 0.649000\n",
      "Loss: 0.852718, Train accuracy: 0.755667, val accuracy: 0.636000\n",
      "Loss: 1.116125, Train accuracy: 0.788444, val accuracy: 0.680000\n",
      "Loss: 1.144043, Train accuracy: 0.781333, val accuracy: 0.647000\n",
      "Loss: 2.175795, Train accuracy: 0.199444, val accuracy: 0.209000\n",
      "Loss: 1.726102, Train accuracy: 0.459000, val accuracy: 0.476000\n",
      "Loss: 1.534982, Train accuracy: 0.548889, val accuracy: 0.544000\n",
      "Loss: 1.425338, Train accuracy: 0.616000, val accuracy: 0.598000\n",
      "Loss: 0.888087, Train accuracy: 0.687333, val accuracy: 0.666000\n",
      "Loss: 0.990835, Train accuracy: 0.687444, val accuracy: 0.654000\n",
      "Loss: 0.758688, Train accuracy: 0.738667, val accuracy: 0.684000\n",
      "Loss: 0.919746, Train accuracy: 0.725333, val accuracy: 0.673000\n",
      "Loss: 0.650279, Train accuracy: 0.765444, val accuracy: 0.682000\n",
      "Loss: 0.778009, Train accuracy: 0.770889, val accuracy: 0.716000\n",
      "Loss: 0.770249, Train accuracy: 0.757111, val accuracy: 0.680000\n",
      "Loss: 1.042380, Train accuracy: 0.785778, val accuracy: 0.686000\n",
      "Loss: 0.714388, Train accuracy: 0.811778, val accuracy: 0.716000\n",
      "Loss: 0.707639, Train accuracy: 0.821667, val accuracy: 0.697000\n",
      "Loss: 0.840148, Train accuracy: 0.831222, val accuracy: 0.735000\n",
      "Loss: 0.900269, Train accuracy: 0.819778, val accuracy: 0.718000\n",
      "Loss: 0.866951, Train accuracy: 0.853222, val accuracy: 0.732000\n",
      "Loss: 0.568708, Train accuracy: 0.822556, val accuracy: 0.712000\n",
      "Loss: 0.846390, Train accuracy: 0.814778, val accuracy: 0.711000\n",
      "Loss: 0.542774, Train accuracy: 0.830000, val accuracy: 0.712000\n",
      "Loss: 2.303130, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287482, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.139751, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.104847, Train accuracy: 0.235333, val accuracy: 0.243000\n",
      "Loss: 1.895833, Train accuracy: 0.296778, val accuracy: 0.302000\n",
      "Loss: 1.961908, Train accuracy: 0.376444, val accuracy: 0.385000\n",
      "Loss: 1.509453, Train accuracy: 0.451444, val accuracy: 0.451000\n",
      "Loss: 1.763673, Train accuracy: 0.518778, val accuracy: 0.507000\n",
      "Loss: 1.362863, Train accuracy: 0.569333, val accuracy: 0.555000\n",
      "Loss: 1.255714, Train accuracy: 0.594556, val accuracy: 0.594000\n",
      "Loss: 1.281106, Train accuracy: 0.628111, val accuracy: 0.622000\n",
      "Loss: 1.312658, Train accuracy: 0.655000, val accuracy: 0.651000\n",
      "Loss: 1.025096, Train accuracy: 0.661444, val accuracy: 0.656000\n",
      "Loss: 1.448185, Train accuracy: 0.663667, val accuracy: 0.662000\n",
      "Loss: 1.464505, Train accuracy: 0.685000, val accuracy: 0.658000\n",
      "Loss: 1.167936, Train accuracy: 0.717444, val accuracy: 0.691000\n",
      "Loss: 1.366710, Train accuracy: 0.718444, val accuracy: 0.688000\n",
      "Loss: 1.180682, Train accuracy: 0.730778, val accuracy: 0.700000\n",
      "Loss: 0.977613, Train accuracy: 0.734778, val accuracy: 0.700000\n",
      "Loss: 1.122450, Train accuracy: 0.749889, val accuracy: 0.719000\n",
      "Loss: 2.303396, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.308762, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178783, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257625, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.323329, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.038450, Train accuracy: 0.207222, val accuracy: 0.214000\n",
      "Loss: 2.122873, Train accuracy: 0.252667, val accuracy: 0.248000\n",
      "Loss: 2.038947, Train accuracy: 0.272778, val accuracy: 0.278000\n",
      "Loss: 1.988031, Train accuracy: 0.292000, val accuracy: 0.298000\n",
      "Loss: 1.816492, Train accuracy: 0.320778, val accuracy: 0.332000\n",
      "Loss: 1.951726, Train accuracy: 0.366889, val accuracy: 0.365000\n",
      "Loss: 1.948631, Train accuracy: 0.411111, val accuracy: 0.395000\n",
      "Loss: 1.657756, Train accuracy: 0.447333, val accuracy: 0.442000\n",
      "Loss: 1.678594, Train accuracy: 0.480000, val accuracy: 0.473000\n",
      "Loss: 1.397893, Train accuracy: 0.510556, val accuracy: 0.514000\n",
      "Loss: 1.517458, Train accuracy: 0.533889, val accuracy: 0.530000\n",
      "Loss: 1.635968, Train accuracy: 0.573667, val accuracy: 0.568000\n",
      "Loss: 1.409926, Train accuracy: 0.601000, val accuracy: 0.595000\n",
      "Loss: 1.341131, Train accuracy: 0.623333, val accuracy: 0.618000\n",
      "Loss: 2.163406, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145887, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152343, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.019552, Train accuracy: 0.265667, val accuracy: 0.262000\n",
      "Loss: 2.069686, Train accuracy: 0.308889, val accuracy: 0.317000\n",
      "Loss: 1.752273, Train accuracy: 0.397111, val accuracy: 0.390000\n",
      "Loss: 1.521047, Train accuracy: 0.476444, val accuracy: 0.469000\n",
      "Loss: 1.663024, Train accuracy: 0.531000, val accuracy: 0.526000\n",
      "Loss: 1.416447, Train accuracy: 0.595333, val accuracy: 0.596000\n",
      "Loss: 1.345919, Train accuracy: 0.625444, val accuracy: 0.610000\n",
      "Loss: 1.025058, Train accuracy: 0.645111, val accuracy: 0.642000\n",
      "Loss: 1.056530, Train accuracy: 0.671556, val accuracy: 0.665000\n",
      "Loss: 1.093300, Train accuracy: 0.690333, val accuracy: 0.669000\n",
      "Loss: 1.213939, Train accuracy: 0.702222, val accuracy: 0.677000\n",
      "Loss: 0.875429, Train accuracy: 0.715111, val accuracy: 0.675000\n",
      "Loss: 1.319339, Train accuracy: 0.726222, val accuracy: 0.697000\n",
      "Loss: 1.034282, Train accuracy: 0.724667, val accuracy: 0.695000\n",
      "Loss: 1.322947, Train accuracy: 0.745111, val accuracy: 0.695000\n",
      "Loss: 1.084912, Train accuracy: 0.753556, val accuracy: 0.716000\n",
      "Loss: 0.848394, Train accuracy: 0.755556, val accuracy: 0.716000\n",
      "Loss: 2.186583, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.139455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296645, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204689, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212087, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142001, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.071971, Train accuracy: 0.231778, val accuracy: 0.237000\n",
      "Loss: 2.179129, Train accuracy: 0.266556, val accuracy: 0.267000\n",
      "Loss: 2.028723, Train accuracy: 0.282000, val accuracy: 0.286000\n",
      "Loss: 2.062035, Train accuracy: 0.327333, val accuracy: 0.332000\n",
      "Loss: 1.985695, Train accuracy: 0.387889, val accuracy: 0.375000\n",
      "Loss: 1.712551, Train accuracy: 0.421556, val accuracy: 0.417000\n",
      "Loss: 1.557924, Train accuracy: 0.440778, val accuracy: 0.434000\n",
      "Loss: 1.540866, Train accuracy: 0.477889, val accuracy: 0.481000\n",
      "Loss: 1.769124, Train accuracy: 0.516889, val accuracy: 0.516000\n",
      "Loss: 1.296800, Train accuracy: 0.543556, val accuracy: 0.543000\n",
      "Loss: 1.515981, Train accuracy: 0.580333, val accuracy: 0.567000\n",
      "Loss: 1.528032, Train accuracy: 0.609111, val accuracy: 0.598000\n",
      "Loss: 1.136681, Train accuracy: 0.619000, val accuracy: 0.605000\n",
      "Loss: 1.348270, Train accuracy: 0.637889, val accuracy: 0.617000\n",
      "Loss: 2.273666, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225308, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.098832, Train accuracy: 0.212333, val accuracy: 0.217000\n",
      "Loss: 1.961862, Train accuracy: 0.272667, val accuracy: 0.271000\n",
      "Loss: 2.128766, Train accuracy: 0.336556, val accuracy: 0.340000\n",
      "Loss: 1.611398, Train accuracy: 0.432111, val accuracy: 0.430000\n",
      "Loss: 1.746996, Train accuracy: 0.503444, val accuracy: 0.495000\n",
      "Loss: 1.497724, Train accuracy: 0.566667, val accuracy: 0.558000\n",
      "Loss: 1.370330, Train accuracy: 0.609333, val accuracy: 0.587000\n",
      "Loss: 1.339726, Train accuracy: 0.640778, val accuracy: 0.632000\n",
      "Loss: 1.168605, Train accuracy: 0.664222, val accuracy: 0.649000\n",
      "Loss: 1.188097, Train accuracy: 0.676556, val accuracy: 0.662000\n",
      "Loss: 1.469849, Train accuracy: 0.700111, val accuracy: 0.679000\n",
      "Loss: 1.208002, Train accuracy: 0.717556, val accuracy: 0.704000\n",
      "Loss: 1.257345, Train accuracy: 0.732778, val accuracy: 0.699000\n",
      "Loss: 1.053537, Train accuracy: 0.731556, val accuracy: 0.712000\n",
      "Loss: 0.788514, Train accuracy: 0.739556, val accuracy: 0.699000\n",
      "Loss: 1.007860, Train accuracy: 0.759889, val accuracy: 0.721000\n",
      "Loss: 0.845360, Train accuracy: 0.754222, val accuracy: 0.730000\n",
      "Loss: 1.101984, Train accuracy: 0.760667, val accuracy: 0.709000\n",
      "Loss: 2.212397, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.165986, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.163671, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.091540, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.126505, Train accuracy: 0.206556, val accuracy: 0.216000\n",
      "Loss: 2.004157, Train accuracy: 0.252556, val accuracy: 0.257000\n",
      "Loss: 2.002693, Train accuracy: 0.277333, val accuracy: 0.275000\n",
      "Loss: 1.818193, Train accuracy: 0.311000, val accuracy: 0.317000\n",
      "Loss: 1.854184, Train accuracy: 0.364556, val accuracy: 0.356000\n",
      "Loss: 1.641374, Train accuracy: 0.416667, val accuracy: 0.403000\n",
      "Loss: 1.783290, Train accuracy: 0.455444, val accuracy: 0.443000\n",
      "Loss: 1.672911, Train accuracy: 0.493111, val accuracy: 0.484000\n",
      "Loss: 1.526113, Train accuracy: 0.529333, val accuracy: 0.521000\n",
      "Loss: 1.445259, Train accuracy: 0.557333, val accuracy: 0.538000\n",
      "Loss: 1.554305, Train accuracy: 0.577222, val accuracy: 0.568000\n",
      "Loss: 1.093313, Train accuracy: 0.601222, val accuracy: 0.584000\n",
      "Loss: 1.431909, Train accuracy: 0.622556, val accuracy: 0.596000\n",
      "Loss: 1.199746, Train accuracy: 0.638556, val accuracy: 0.619000\n",
      "Loss: 1.338061, Train accuracy: 0.650000, val accuracy: 0.634000\n",
      "Loss: 2.176041, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.356149, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.106264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.085042, Train accuracy: 0.248333, val accuracy: 0.246000\n",
      "Loss: 1.919087, Train accuracy: 0.306111, val accuracy: 0.305000\n",
      "Loss: 1.815072, Train accuracy: 0.386667, val accuracy: 0.379000\n",
      "Loss: 1.468508, Train accuracy: 0.465444, val accuracy: 0.461000\n",
      "Loss: 1.382733, Train accuracy: 0.521889, val accuracy: 0.511000\n",
      "Loss: 1.138234, Train accuracy: 0.584333, val accuracy: 0.576000\n",
      "Loss: 1.277086, Train accuracy: 0.627000, val accuracy: 0.608000\n",
      "Loss: 1.133130, Train accuracy: 0.642889, val accuracy: 0.615000\n",
      "Loss: 0.836694, Train accuracy: 0.667556, val accuracy: 0.648000\n",
      "Loss: 1.199433, Train accuracy: 0.695222, val accuracy: 0.668000\n",
      "Loss: 0.887330, Train accuracy: 0.695111, val accuracy: 0.669000\n",
      "Loss: 0.781080, Train accuracy: 0.717667, val accuracy: 0.694000\n",
      "Loss: 0.994865, Train accuracy: 0.722000, val accuracy: 0.702000\n",
      "Loss: 1.084489, Train accuracy: 0.730556, val accuracy: 0.693000\n",
      "Loss: 0.825944, Train accuracy: 0.738000, val accuracy: 0.700000\n",
      "Loss: 0.836101, Train accuracy: 0.754556, val accuracy: 0.716000\n",
      "Loss: 1.015553, Train accuracy: 0.756111, val accuracy: 0.716000\n",
      "Loss: 2.279017, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210705, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205820, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306292, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212227, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.072585, Train accuracy: 0.216889, val accuracy: 0.216000\n",
      "Loss: 1.994522, Train accuracy: 0.252778, val accuracy: 0.251000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.941048, Train accuracy: 0.276444, val accuracy: 0.281000\n",
      "Loss: 1.828984, Train accuracy: 0.303111, val accuracy: 0.307000\n",
      "Loss: 2.012902, Train accuracy: 0.357889, val accuracy: 0.361000\n",
      "Loss: 1.967323, Train accuracy: 0.403778, val accuracy: 0.393000\n",
      "Loss: 1.687404, Train accuracy: 0.449111, val accuracy: 0.439000\n",
      "Loss: 1.626283, Train accuracy: 0.483667, val accuracy: 0.466000\n",
      "Loss: 1.401835, Train accuracy: 0.512778, val accuracy: 0.508000\n",
      "Loss: 1.508316, Train accuracy: 0.539556, val accuracy: 0.529000\n",
      "Loss: 1.483283, Train accuracy: 0.579111, val accuracy: 0.571000\n",
      "Loss: 1.481216, Train accuracy: 0.595778, val accuracy: 0.581000\n",
      "Loss: 1.191793, Train accuracy: 0.599556, val accuracy: 0.585000\n",
      "Loss: 1.155780, Train accuracy: 0.626667, val accuracy: 0.621000\n",
      "Loss: 2.225541, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195403, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251321, Train accuracy: 0.200444, val accuracy: 0.207000\n",
      "Loss: 2.088840, Train accuracy: 0.273333, val accuracy: 0.274000\n",
      "Loss: 1.904114, Train accuracy: 0.310778, val accuracy: 0.321000\n",
      "Loss: 1.630985, Train accuracy: 0.419000, val accuracy: 0.415000\n",
      "Loss: 1.615000, Train accuracy: 0.486000, val accuracy: 0.486000\n",
      "Loss: 1.355331, Train accuracy: 0.537667, val accuracy: 0.542000\n",
      "Loss: 1.363314, Train accuracy: 0.594333, val accuracy: 0.589000\n",
      "Loss: 1.420586, Train accuracy: 0.636000, val accuracy: 0.630000\n",
      "Loss: 1.349444, Train accuracy: 0.665444, val accuracy: 0.656000\n",
      "Loss: 1.247708, Train accuracy: 0.672778, val accuracy: 0.670000\n",
      "Loss: 1.198004, Train accuracy: 0.701556, val accuracy: 0.690000\n",
      "Loss: 0.852707, Train accuracy: 0.716556, val accuracy: 0.693000\n",
      "Loss: 0.949702, Train accuracy: 0.731444, val accuracy: 0.684000\n",
      "Loss: 0.871031, Train accuracy: 0.734333, val accuracy: 0.697000\n",
      "Loss: 0.967388, Train accuracy: 0.748222, val accuracy: 0.707000\n",
      "Loss: 0.922347, Train accuracy: 0.755333, val accuracy: 0.700000\n",
      "Loss: 0.881502, Train accuracy: 0.766333, val accuracy: 0.717000\n",
      "Loss: 0.755760, Train accuracy: 0.768667, val accuracy: 0.720000\n",
      "Loss: 2.251743, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198691, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197075, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217733, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253018, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.100406, Train accuracy: 0.240111, val accuracy: 0.249000\n",
      "Loss: 2.042135, Train accuracy: 0.272444, val accuracy: 0.270000\n",
      "Loss: 2.176007, Train accuracy: 0.298000, val accuracy: 0.304000\n",
      "Loss: 1.590172, Train accuracy: 0.343667, val accuracy: 0.336000\n",
      "Loss: 1.927398, Train accuracy: 0.404000, val accuracy: 0.397000\n",
      "Loss: 1.563854, Train accuracy: 0.438111, val accuracy: 0.420000\n",
      "Loss: 1.562462, Train accuracy: 0.478111, val accuracy: 0.467000\n",
      "Loss: 1.499600, Train accuracy: 0.518889, val accuracy: 0.515000\n",
      "Loss: 1.735406, Train accuracy: 0.544333, val accuracy: 0.539000\n",
      "Loss: 1.354007, Train accuracy: 0.558667, val accuracy: 0.548000\n",
      "Loss: 1.492680, Train accuracy: 0.591667, val accuracy: 0.572000\n",
      "Loss: 1.295683, Train accuracy: 0.605000, val accuracy: 0.582000\n",
      "Loss: 1.055390, Train accuracy: 0.632000, val accuracy: 0.611000\n",
      "Loss: 1.463090, Train accuracy: 0.647111, val accuracy: 0.628000\n",
      "Loss: 2.285258, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225869, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.046855, Train accuracy: 0.204556, val accuracy: 0.212000\n",
      "Loss: 1.983034, Train accuracy: 0.278444, val accuracy: 0.277000\n",
      "Loss: 1.721331, Train accuracy: 0.352556, val accuracy: 0.357000\n",
      "Loss: 1.653961, Train accuracy: 0.438556, val accuracy: 0.433000\n",
      "Loss: 1.403259, Train accuracy: 0.514889, val accuracy: 0.506000\n",
      "Loss: 1.353690, Train accuracy: 0.581444, val accuracy: 0.568000\n",
      "Loss: 1.183690, Train accuracy: 0.616111, val accuracy: 0.599000\n",
      "Loss: 1.240944, Train accuracy: 0.659889, val accuracy: 0.642000\n",
      "Loss: 1.319962, Train accuracy: 0.661333, val accuracy: 0.644000\n",
      "Loss: 0.745818, Train accuracy: 0.690778, val accuracy: 0.678000\n",
      "Loss: 1.262632, Train accuracy: 0.712000, val accuracy: 0.693000\n",
      "Loss: 1.004577, Train accuracy: 0.721778, val accuracy: 0.699000\n",
      "Loss: 1.211293, Train accuracy: 0.746333, val accuracy: 0.718000\n",
      "Loss: 0.628744, Train accuracy: 0.737333, val accuracy: 0.696000\n",
      "Loss: 0.790715, Train accuracy: 0.761889, val accuracy: 0.725000\n",
      "Loss: 0.696342, Train accuracy: 0.763333, val accuracy: 0.706000\n",
      "Loss: 0.798378, Train accuracy: 0.780222, val accuracy: 0.732000\n",
      "Loss: 0.645134, Train accuracy: 0.782222, val accuracy: 0.724000\n",
      "Loss: 2.218520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253534, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.119381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210597, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.158758, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.030121, Train accuracy: 0.209111, val accuracy: 0.218000\n",
      "Loss: 2.157667, Train accuracy: 0.253222, val accuracy: 0.253000\n",
      "Loss: 1.944425, Train accuracy: 0.273556, val accuracy: 0.274000\n",
      "Loss: 2.062184, Train accuracy: 0.314111, val accuracy: 0.321000\n",
      "Loss: 2.137247, Train accuracy: 0.375444, val accuracy: 0.368000\n",
      "Loss: 1.503788, Train accuracy: 0.411222, val accuracy: 0.407000\n",
      "Loss: 1.557293, Train accuracy: 0.461889, val accuracy: 0.455000\n",
      "Loss: 1.712015, Train accuracy: 0.508111, val accuracy: 0.509000\n",
      "Loss: 1.487385, Train accuracy: 0.539222, val accuracy: 0.536000\n",
      "Loss: 1.641861, Train accuracy: 0.566778, val accuracy: 0.559000\n",
      "Loss: 1.296194, Train accuracy: 0.595444, val accuracy: 0.581000\n",
      "Loss: 1.351170, Train accuracy: 0.615444, val accuracy: 0.599000\n",
      "Loss: 1.285653, Train accuracy: 0.639222, val accuracy: 0.620000\n",
      "Loss: 1.201397, Train accuracy: 0.649889, val accuracy: 0.639000\n",
      "Loss: 1.102919, Train accuracy: 0.654333, val accuracy: 0.637000\n",
      "Loss: 2.255777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231895, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.930951, Train accuracy: 0.246667, val accuracy: 0.243000\n",
      "Loss: 2.075349, Train accuracy: 0.276778, val accuracy: 0.273000\n",
      "Loss: 2.032329, Train accuracy: 0.353000, val accuracy: 0.355000\n",
      "Loss: 1.661430, Train accuracy: 0.436000, val accuracy: 0.423000\n",
      "Loss: 1.454107, Train accuracy: 0.503556, val accuracy: 0.497000\n",
      "Loss: 1.498375, Train accuracy: 0.542000, val accuracy: 0.534000\n",
      "Loss: 1.020609, Train accuracy: 0.600333, val accuracy: 0.595000\n",
      "Loss: 1.050926, Train accuracy: 0.636111, val accuracy: 0.610000\n",
      "Loss: 1.234794, Train accuracy: 0.666778, val accuracy: 0.649000\n",
      "Loss: 1.053249, Train accuracy: 0.672111, val accuracy: 0.657000\n",
      "Loss: 1.053672, Train accuracy: 0.695778, val accuracy: 0.679000\n",
      "Loss: 1.121102, Train accuracy: 0.713222, val accuracy: 0.682000\n",
      "Loss: 1.050774, Train accuracy: 0.725000, val accuracy: 0.695000\n",
      "Loss: 0.672090, Train accuracy: 0.726333, val accuracy: 0.697000\n",
      "Loss: 0.808928, Train accuracy: 0.735778, val accuracy: 0.704000\n",
      "Loss: 0.859117, Train accuracy: 0.746889, val accuracy: 0.712000\n",
      "Loss: 0.606672, Train accuracy: 0.749889, val accuracy: 0.712000\n",
      "Loss: 2.239414, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235879, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314823, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278680, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184282, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.146104, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.048555, Train accuracy: 0.221444, val accuracy: 0.229000\n",
      "Loss: 2.093946, Train accuracy: 0.269556, val accuracy: 0.265000\n",
      "Loss: 2.063670, Train accuracy: 0.280111, val accuracy: 0.281000\n",
      "Loss: 1.890808, Train accuracy: 0.303667, val accuracy: 0.316000\n",
      "Loss: 1.789935, Train accuracy: 0.366667, val accuracy: 0.361000\n",
      "Loss: 1.793300, Train accuracy: 0.408667, val accuracy: 0.398000\n",
      "Loss: 1.394990, Train accuracy: 0.449778, val accuracy: 0.451000\n",
      "Loss: 1.587843, Train accuracy: 0.469111, val accuracy: 0.468000\n",
      "Loss: 1.293024, Train accuracy: 0.500889, val accuracy: 0.483000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.513328, Train accuracy: 0.530111, val accuracy: 0.530000\n",
      "Loss: 1.253293, Train accuracy: 0.568556, val accuracy: 0.553000\n",
      "Loss: 1.175275, Train accuracy: 0.593000, val accuracy: 0.578000\n",
      "Loss: 1.570879, Train accuracy: 0.614222, val accuracy: 0.595000\n",
      "Loss: 1.234937, Train accuracy: 0.632556, val accuracy: 0.608000\n",
      "Loss: 2.208217, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239231, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292564, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.072635, Train accuracy: 0.267444, val accuracy: 0.264000\n",
      "Loss: 1.921306, Train accuracy: 0.319444, val accuracy: 0.324000\n",
      "Loss: 1.820893, Train accuracy: 0.411111, val accuracy: 0.418000\n",
      "Loss: 1.618064, Train accuracy: 0.486333, val accuracy: 0.478000\n",
      "Loss: 1.577142, Train accuracy: 0.548556, val accuracy: 0.526000\n",
      "Loss: 1.220129, Train accuracy: 0.599333, val accuracy: 0.570000\n",
      "Loss: 1.059774, Train accuracy: 0.622667, val accuracy: 0.603000\n",
      "Loss: 1.232970, Train accuracy: 0.666889, val accuracy: 0.648000\n",
      "Loss: 1.198984, Train accuracy: 0.679222, val accuracy: 0.661000\n",
      "Loss: 1.047185, Train accuracy: 0.695889, val accuracy: 0.676000\n",
      "Loss: 1.004420, Train accuracy: 0.710778, val accuracy: 0.685000\n",
      "Loss: 0.917335, Train accuracy: 0.714556, val accuracy: 0.684000\n",
      "Loss: 0.846472, Train accuracy: 0.732333, val accuracy: 0.695000\n",
      "Loss: 0.876143, Train accuracy: 0.741778, val accuracy: 0.699000\n",
      "Loss: 0.688187, Train accuracy: 0.752444, val accuracy: 0.704000\n",
      "Loss: 0.955596, Train accuracy: 0.769556, val accuracy: 0.711000\n",
      "Loss: 0.528412, Train accuracy: 0.780556, val accuracy: 0.717000\n",
      "Loss: 2.276937, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.131411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273914, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243693, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.341880, Train accuracy: 0.198000, val accuracy: 0.208000\n",
      "Loss: 2.145921, Train accuracy: 0.236889, val accuracy: 0.241000\n",
      "Loss: 1.934255, Train accuracy: 0.267111, val accuracy: 0.264000\n",
      "Loss: 1.823854, Train accuracy: 0.288667, val accuracy: 0.293000\n",
      "Loss: 2.045599, Train accuracy: 0.337556, val accuracy: 0.343000\n",
      "Loss: 1.543990, Train accuracy: 0.388778, val accuracy: 0.380000\n",
      "Loss: 1.644749, Train accuracy: 0.424444, val accuracy: 0.413000\n",
      "Loss: 1.520336, Train accuracy: 0.465222, val accuracy: 0.455000\n",
      "Loss: 1.475748, Train accuracy: 0.495667, val accuracy: 0.495000\n",
      "Loss: 1.391911, Train accuracy: 0.544333, val accuracy: 0.535000\n",
      "Loss: 1.524624, Train accuracy: 0.556444, val accuracy: 0.542000\n",
      "Loss: 1.585878, Train accuracy: 0.586444, val accuracy: 0.570000\n",
      "Loss: 1.366289, Train accuracy: 0.609667, val accuracy: 0.585000\n",
      "Loss: 1.485200, Train accuracy: 0.625000, val accuracy: 0.607000\n",
      "Loss: 1.112454, Train accuracy: 0.639444, val accuracy: 0.613000\n",
      "Loss: 2.153663, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190242, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201592, Train accuracy: 0.217556, val accuracy: 0.224000\n",
      "Loss: 2.109099, Train accuracy: 0.277111, val accuracy: 0.280000\n",
      "Loss: 1.769543, Train accuracy: 0.346333, val accuracy: 0.350000\n",
      "Loss: 1.789769, Train accuracy: 0.441778, val accuracy: 0.453000\n",
      "Loss: 1.390369, Train accuracy: 0.515111, val accuracy: 0.500000\n",
      "Loss: 1.456785, Train accuracy: 0.576444, val accuracy: 0.569000\n",
      "Loss: 1.323443, Train accuracy: 0.632889, val accuracy: 0.612000\n",
      "Loss: 1.204318, Train accuracy: 0.651111, val accuracy: 0.634000\n",
      "Loss: 1.081589, Train accuracy: 0.666444, val accuracy: 0.635000\n",
      "Loss: 1.230926, Train accuracy: 0.697000, val accuracy: 0.672000\n",
      "Loss: 1.218404, Train accuracy: 0.718667, val accuracy: 0.701000\n",
      "Loss: 0.918337, Train accuracy: 0.726778, val accuracy: 0.684000\n",
      "Loss: 0.826688, Train accuracy: 0.727889, val accuracy: 0.696000\n",
      "Loss: 0.759161, Train accuracy: 0.749222, val accuracy: 0.706000\n",
      "Loss: 1.028642, Train accuracy: 0.749889, val accuracy: 0.703000\n",
      "Loss: 0.745532, Train accuracy: 0.775333, val accuracy: 0.723000\n",
      "Loss: 0.663009, Train accuracy: 0.780111, val accuracy: 0.711000\n",
      "Loss: 0.548749, Train accuracy: 0.789444, val accuracy: 0.722000\n",
      "Loss: 2.234722, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282007, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.143845, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190820, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.067520, Train accuracy: 0.211778, val accuracy: 0.219000\n",
      "Loss: 2.051128, Train accuracy: 0.261556, val accuracy: 0.257000\n",
      "Loss: 2.122177, Train accuracy: 0.283889, val accuracy: 0.284000\n",
      "Loss: 1.896878, Train accuracy: 0.305222, val accuracy: 0.310000\n",
      "Loss: 1.972003, Train accuracy: 0.364889, val accuracy: 0.361000\n",
      "Loss: 1.680357, Train accuracy: 0.406778, val accuracy: 0.391000\n",
      "Loss: 1.584785, Train accuracy: 0.449333, val accuracy: 0.436000\n",
      "Loss: 1.705007, Train accuracy: 0.492222, val accuracy: 0.485000\n",
      "Loss: 1.597040, Train accuracy: 0.534333, val accuracy: 0.531000\n",
      "Loss: 1.317313, Train accuracy: 0.564667, val accuracy: 0.555000\n",
      "Loss: 1.042182, Train accuracy: 0.590111, val accuracy: 0.565000\n",
      "Loss: 1.534643, Train accuracy: 0.613333, val accuracy: 0.603000\n",
      "Loss: 0.820662, Train accuracy: 0.622444, val accuracy: 0.599000\n",
      "Loss: 1.042453, Train accuracy: 0.649111, val accuracy: 0.619000\n",
      "Loss: 1.063061, Train accuracy: 0.665222, val accuracy: 0.648000\n",
      "Loss: 2.275264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287600, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306896, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233110, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306715, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269123, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208580, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.222522, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237789, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181791, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233740, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294060, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152730, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250703, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291910, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276855, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271903, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266415, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267100, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274921, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247926, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256225, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202443, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193487, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191960, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.167871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190930, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.185464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255710, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293397, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285113, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.265435, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263250, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205593, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248026, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296302, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223852, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219645, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.089050, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276563, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250006, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260771, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.344112, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288280, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264007, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.113864, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223950, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296161, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283085, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239228, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244604, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233957, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275460, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270017, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251924, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247939, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315340, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238897, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193071, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294062, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225043, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.157380, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265983, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295342, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281937, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281911, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284972, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287565, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210599, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257370, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245663, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.130152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216017, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253621, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229207, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217134, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317343, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228894, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190948, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.340688, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.089493, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212596, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290208, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285613, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256572, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235667, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249468, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259246, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248146, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280462, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201325, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301607, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237195, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.167272, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281533, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314793, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216667, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233168, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.150700, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241227, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292127, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268527, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294268, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237693, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217925, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.313715, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251058, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286398, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154478, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314729, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.145441, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247382, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280809, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205478, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319682, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.125698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277021, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.200275, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275364, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281220, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263534, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292810, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254695, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274689, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243878, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267407, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242173, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187573, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.272357, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266012, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261981, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.200031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172393, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287756, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248479, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294552, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205506, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245548, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281929, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319293, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.131509, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273739, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259242, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245009, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216165, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173688, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226586, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310119, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214391, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183340, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.106174, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295407, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275227, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281610, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261172, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269110, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238825, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283446, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299275, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285376, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233565, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.165212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212013, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.352986, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230158, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207480, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287498, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273165, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204324, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237376, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179573, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.152488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.337182, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.313084, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.093507, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240087, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311603, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153810, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290486, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231916, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208774, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247836, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161130, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216778, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291793, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277561, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251350, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257673, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274332, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.232460, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194313, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249320, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230936, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267200, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183981, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247967, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.121116, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.092523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.149243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.099276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285829, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264380, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260114, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253864, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208281, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240253, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250458, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273409, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203061, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315213, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198266, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183348, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d28d133fc3c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMomentumSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mtemp_loss_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_train_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_val_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtemp_val_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\dl\\dlcourse_ai\\assignments\\assignment2\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             train_accuracy = self.compute_accuracy(self.dataset.train_X,\n\u001b[1;32m--> 123\u001b[1;33m                                                    self.dataset.train_y)\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             val_accuracy = self.compute_accuracy(self.dataset.val_X,\n",
      "\u001b[1;32m~\\Documents\\dl\\dlcourse_ai\\assignments\\assignment2\\trainer.py\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_indices\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mbatch_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mpred_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\dl\\dlcourse_ai\\assignments\\assignment2\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m#raise Exception(\"Not implemented!\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mto_relu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mto_output_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_relu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_output_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\dl\\dlcourse_ai\\assignments\\assignment2\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m#raise Exception(\"Not implemented!\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "learning_rates = [1e-1, 1e-2, 1e-3]\n",
    "reg_strength = [1e-3, 1e-4, 1e-5]\n",
    "hidden_layer_sizes = [64, 128, 256]\n",
    "batch_size = [64, 128]\n",
    "num_epochs = 20\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strength:\n",
    "        for ls in hidden_layer_sizes:\n",
    "            for bs in batch_size:\n",
    "                model = TwoLayerNet(n_input=train_X.shape[1], n_output=10, hidden_layer_size=ls, reg=rs)\n",
    "                trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=lr, num_epochs=num_epochs, batch_size=bs)\n",
    "                temp_loss_history, temp_train_history, temp_val_history = trainer.fit()\n",
    "                \n",
    "                if temp_val_history[-1] > best_val_accuracy:\n",
    "                    best_classifier = model\n",
    "                    best_val_accuracy = temp_val_history[-1]\n",
    "                    loss_history = temp_loss_history.copy()\n",
    "                    train_history = temp_train_history.copy()\n",
    "                    val_history = temp_val_history.copy()\n",
    "    \n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation accuracy achieved: 0.724000\n"
     ]
    }
   ],
   "source": [
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22b3be88108>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAGrCAYAAACBjHUSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXicV333//dXu0bLaLUka7G8JsQOSWzHJmQHkjhhCZAEEgJlS1MoULYuT/troQ8tLT/a0oayhABpCIUAWYAAWWkISchm2U1iO87iNZYly9r3Xd/nj/uWPJIlW7ZljZbP67p0zcw55545o9sj6eNz7nPM3REREREREZGZLyHeHRAREREREZHJUYATERERERGZJRTgREREREREZgkFOBERERERkVlCAU5ERERERGSWUIATERERERGZJRTgREREREREZgkFOBERmfPMbI+ZvSXe/RARETlRCnAiIiIiIiKzhAKciIjMW2b2x2a2w8yazOxeM1sYlpuZ/buZHTSzVjN7wcxWhXVXmNmLZtZuZvvN7M/j+y5ERGQ+UYATEZF5yczeBPwz8B6gBNgL/CSsvhS4AFgB5ADvBRrDuu8Df+LuWcAq4JFp7LaIiMxzSfHugIiISJxcD9zq7psBzOyvgWYzqwT6gSzgVOBZd98ec1w/cJqZPe/uzUDztPZaRETmNY3AiYjIfLWQYNQNAHfvIBhlK3X3R4BvAN8E6szsFjPLDpteBVwB7DWz35vZOdPcbxERmccU4EREZL6qARYNPzCzDCAf2A/g7l939zXASoKplH8Rlm909yuBBcAvgJ9Nc79FRGQeU4ATEZH5ItnM0oa/CILXh83sTDNLBf4JeMbd95jZ2Wa23sySgU6gBxg0sxQzu97Mou7eD7QBg3F7RyIiMu8owImIyHxxH9Ad83U+8HfA3UAtsBS4NmybDXyX4Pq2vQRTK/81rPsAsMfM2oCPAe+fpv6LiIhg7h7vPoiIiIiIiMgkaARORERERERkllCAExERERERmSUU4ERERERERGYJBTgREREREZFZIineHRhPQUGBV1ZWxrsbIiIiIiIicbFp06YGdy8cWz4jA1xlZSVVVVXx7oaIiIiIiEhcmNne8co1hVJERERERGSWUIATERERERGZJRTgREREREREZomjBjgzKzez35nZdjPbZmafHqfN9Wb2Qvj1pJmdEVO3x8y2mNlzZqYL20RERERERI7TZBYxGQA+7+6bzSwL2GRmD7v7izFtdgMXunuzmV0O3AKsj6m/2N0bpq7bIiIiIiIi889RA5y71wK14f12M9sOlAIvxrR5MuaQp4GyKe5nXLV29fMPv3mR3EgyOZEUciLJ5KSnjHqcG0khPSUx3l0VEREREZE57Ji2ETCzSuAs4JkjNPsocH/MYwceMjMHvuPut0zw3DcCNwJUVFQcS7dOutbufv6wo4GWrn66+wcnbJealDAS5qLpwW1uRjLRkbAXBL7c4RAYBsGUJF2KKCIiIiIiR2fuPrmGZpnA74Evu/s9E7S5GPgWcJ67N4ZlC929xswWAA8Dn3L3x470WmvXrvWZug9cT/8grd39NHf10dzZT2t3H81d/bR09dPS1UdzV194v5+Wkbo++gcn/j5npCSOGskbDnfB/RRy0pNHBcHcSArZ6ckkJtg0vnMREREREZkuZrbJ3deOLZ/UCJyZJQN3Az86Qnh7PfA94PLh8Abg7jXh7UEz+zmwDjhigJvJ0pITSUtOpCg7bdLHuDtdfYOjwl1zVx8t3f20dIYhr7tvJATWtHTT3NVHa3c/QxPkPjPITksmN5JMNBIEuwVZqRRlp7EgO43i7DSKslMpzk4jPzNVYU9EREREZA44aoAzMwO+D2x3969N0KYCuAf4gLu/ElOeASSE185lAJcCX5qSns8iZkZGahIZqUmU5U7+uKEhp71nYGQkr7mrj9bh8Dcy4tdPS3c/jR19bK9to76997DQl5hgFGamUpSdOircFWWnUZSdRnE0jaKsNLLTkwhOt4iIiIiIzESTGYE7F/gAsMXMngvL/gaoAHD3m4EvAPnAt8IAMBAO9xUBPw/LkoAfu/sDU/oO5rCEBCMaSSYaSWZR/uSOGRxyGjt6OdDWQ11bcHuwrYcDrT3Utfeyr6mLjXuaaOnqP+zYtOSEINRlpVEUTaMoK5XiaNphoS8tWYu1iIiIiIjEw6SvgZtOM/kauLmip3+Qg2291LWH4a6th4PtvSP369p6ONDWQ0//0GHHRtOTR4/gheHuUNBLoyAzhaRELc4iIiIiInI8TugaOJl70pITqciPUJEfmbCNu9PWM8DBmNG8urbYgNfLjoMNHGzvZXDMvM0Eg4LMcAQvK43iaCorF0ZZtziPJQUZmqopIiIiInIcFOBkQmZGND2ZaHoyy4uyJmw3OOQ0dvZysC0cwWvvoa41CH117T1UN3fx7O5G/vvp1wAoyEzh7Mo8zq7MY93iPF5Xkq1FVkREREREJkEBTk5YYoKxICsYaVtVGh23jbuzu6GTjXuaeGZ3E8/ubuL+rQcAyEpNYk1lLmdX5rF+cR6nl0VJTdJ1diIiIiIiYynAybQwM5YUZrKkMJP3nh1s1F7T0s3GPUGYe3Z3E4++/DIQbIh+ZnkO6xYHI3SrK3LJSNU/VRERERERLWIiM0ZTZ99IoNu4p4mt+1sZ8mCEb9XCbNYtzhuZepmbkRLv7oqIiIiInDQTLWKiACczVkfvAJv3NgcjdHuaeG5fC30DwaqYK4oywxG6fNZV5lEcnfzG6iIiIiIiM50CnMx6Pf2DvFDdOnId3ea9zXT0DgBQkRcZuYbu7MV5VOZHtNKliIiIiMxaCnAy5wwMDrG9tp1n9zTx7O5GNu5ppqmzD4DCrFTWhatcrlucxylFWSRopUsRERERmSUU4GTOc3d21nfwzO4mNoYLo9S09gCQnZYUXD8XBrpVC6OkJGmjcRERERGZmbSRt8x5ZsayBVksW5DF9esXAYR70DWNXEf3Py8dBCAtOYHVFYe2LjirIpf0FG1dICIiIiIzmwKczGlluRHKciO8e3UZAPXtvVSF19Bt3NPE1x95FXdISjDOX17AVWvKeMvrikhLVpgTERERkZlHUyhlXmvt7mfz3mae2tXIr56voba1h+y0JN5x5kKuXlPOGWVRLYYiIiIiItNO18CJHMXgkPPkzgbu2lTNA1sP0DswxLIFmVy1uox3nVWqrQpEREREZNoowIkcg7aefu57oZa7NlVTtbeZBIPzlxdy9ZoyLjlNUyxFRERE5ORSgBM5TrsbOrl7UzX3bK6mprWHrLQk3n7GQq5eU8ZZ5TmaYikiIiIiU04BTuQEDQ05T+1q5K5N1dy/tZae/iGWFGRw1Zoy3r26lJJoery7KCIiIiJzhAKcyBRq7+nn/i0HuGtTNc/uacIMzltWwNVryrj0tGJtSSAiIiIiJ0QBTuQk2dvYyd2b93P3pmr2t3STlZrE284o4arVZaxZlKspliIiIiJyzI47wJlZOXA7UAwMAbe4+01j2hhwE3AF0AV8yN03h3UfBP42bPqP7v6Do3VWAU5mo6Eh5+ndjdy9aT/3bamlu3+QxQUZXLW6lHetLqM0R1MsRURERGRyTiTAlQAl7r7ZzLKATcA73f3FmDZXAJ8iCHDrgZvcfb2Z5QFVwFrAw2PXuHvzkV5TAU5mu47eAe7fEqxi+czuYIrlG5fmc/WaMjasLNEUSxERERE5ookCXNLRDnT3WqA2vN9uZtuBUuDFmGZXArd7kAafNrOcMPhdBDzs7k1hJx4GNgB3nOD7EZnRMlOTuGZtOdesLWdfUxd3b67m7s3VfPanz/N3qdt46+klXL22jLWaYikiIiIix+CoAS6WmVUCZwHPjKkqBfbFPK4OyyYqH++5bwRuBKioqDiWbonMaOV5ET7zlhX82ZuWs3FPE3dtquZXL9Tw06p9LMqPcNXqYBXLstxIvLsqIiIiIjPcpAOcmWUCdwOfcfe2sdXjHOJHKD+80P0W4BYIplBOtl8is0VCgrF+ST7rl+Tzf69cyQNbg1Usv/bwK3zt4Vc4Z0kwxfLy04uJpBzT/62IiIiIyDwxqb8SzSyZILz9yN3vGadJNVAe87gMqAnLLxpT/ujxdFRkLomkJPHu1WW8e3UZ1c1d3LN5P3dvrubzdz7PF365lStOL+GqNWWsq8wjIUFTLEVEREQkMJlFTAz4AdDk7p+ZoM1bgU9yaBGTr7v7unARk03A6rDpZoJFTJqO9JpaxETmI3enam8zd1VV85sttXT0DlCel85Vq8u4anUZ5XmaYikiIiIyX5zIKpTnAY8DWwi2EQD4G6ACwN1vDkPeNwgWKOkCPuzuVeHxHwnbA3zZ3f/raJ1VgJP5rrtvkAe3BVMs/7CzAXe45LQi/uKyU1hRlBXv7omIiIjISaaNvEVmqZqWbn66cR+3PrGbzr4B3r26jM+8ZbkWPRERERGZwxTgRGa55s4+vv37ndz25B5weP8bFvGJi5eSn5ka766JiIiIyBRTgBOZI2paurnpt69y56Z9RFKS+OPzl/DR8xeTmaqVK0VERETmCgU4kTlmx8EO/u2hl7l/6wHyM1L41JuWcd36ClKTEuPdNRERERE5QQpwInPUc/ta+OoDL/HkzkbKctP53CUruPLMUhK1/YCIiIjIrDVRgEuIR2dEZOqcWZ7Dj25Yzw8/uo6cSDKf+9nzvPXrj/M/2+uYif9BIyIiIiLHTwFOZA4wM85fXsi9nziPb75vNb0DQ3z0B1Vcc/NTbNxzxG0XRURERGQWUYATmUMSEoy3vr6Ehz57Af/0rtN5ramLa25+io/etpHttW3x7p6IiIiInCBdAycyh3X3DXLbk3v49qM7aO8d4J1nlvK5S1ZQnqc95ERERERmMi1iIjKPtXb1c/NjO/mvP+xmcMi5fv0iPnHxMgqztIeciIiIyEykACci1LX1cNP/vMpPN+4jNSmBG85bzB9fsISstOR4d01EREREYijAiciI3Q2d/NtDL/PrF2rJjSTziYuX8f43LCItWXvIiYiIiMwECnAicpgt1a189cGXePzVBhZG0/jMJSt491mlJCVqfSMRERGReNI+cCJymNPLovzwo+v58Q3rKcxO4y/veoENNz3Og9sOaA85ERERkRlIAU5EeOOyAn7xp2/k5vevxt35kx9u4l3fepKndjbGu2siIiIiEkMBTkSAYDPwDatKePAzF/DVq15PXVsP1333af7o1mfZur813t0TEREREXQNnIhMoKd/kB8+tZdvPrqDlq5+3n7GQj5/yQoqCzLi3TURERGROU+LmIjIcWnr6eeW3+/i+0/spn9wiPeeXc6n37ycBdlp8e6aiIiIyJx13AHOzG4F3gYcdPdV49T/BXB9+DAJeB1Q6O5NZrYHaAcGgYHxOjAeBTiRmedgew/feGQHP37mNZISjY+cu5g/uXAp0XTtISciIiIy1U4kwF0AdAC3jxfgxrR9O/BZd39T+HgPsNbdG46lswpwIjPX3sZOvvbwK/zyuRqi6cn86UVL+eAbK7WHnIiIiMgUOu5tBNz9MaBpkq9zHXDHMfZNRGaRRfkZ3HTtWfzmz85jdUUO/3z/S1z0L49y+1N76OkfjHf3REREROa0SV0DZ2aVwK+PNAJnZhGgGljm7k1h2W6gGXDgO+5+yxGOvxG4EaCiomLN3r17J/8uRCRuntnVyL88+DJVe5spyEzhw+cu5v1vWKSplSIiIiIn4IQWMZlkgHsv8H53f3tM2UJ3rzGzBcDDwKfCEb0j0hRKkdnF3Xl2dxPfenQnv3+lnszUJK5/QwUfPW8xC7K02ImIiIjIsZoowCVN4Wtcy5jpk+5eE94eNLOfA+uAowY4EZldzIz1S/JZvySfbTWt3Pz7XXz3sV381x/2cPWaMv7kgiUsytf2AyIiIiInako28jazKHAh8MuYsgwzyxq+D1wKbJ2K1xORmWvlwij/ed1ZPPL5i7h6TRl3VVVz8b8+yqfu+F+21WhDcBEREZETMZlVKO8ALgIKgDrgi0AygLvfHLb5ELDB3a+NOW4J8PPwYRLwY3f/8mQ6pSmUInPHwbYebv3DHv776b109A5w4YpCPn7RUtYvzsPM4t09ERERkRlJG3mLSFy1dvfz30/v5b/+sJuGjj5WV+Tw8YuW8eZTF5CQoCAnIiIiEksBTkRmhJ7+Qe6s2sd3HttFdXM3K4oy+diFS3n7GQtJTpySWd0iIiIis54CnIjMKAODQ/xmSy3ffnQnLx1opzQnnT8+fzHvPbuC9BRtCi4iIiLzmwKciMxI7s7vXj7Itx/dycY9zeRlpPDhN1byR+dUEo1oLzkRERGZnxTgRGTG27iniW8/upNHXjpIRkoi71tfwQ3nL6EoW3vJiYiIyPyiACcis8b22ja+8/ud/OqFWhLNePfqUm68YAlLCjPj3TURERGRaaEAJyKzzmuNXXz38V38rGoffYNDXL6qmI9fuIzTy6Lx7pqIiIjISaUAJyKzVn17L7c9uZvbn9pLe88A5y8v4OMXLuWcpfnaS05ERETmJAU4EZn12nr6+fEzr/G9x3fT0NHLGeU5fPzCpVx6WpH2khMREZE5RQFOROaMnv5B7t5czXd+v4vXmrpYWpjBxy5cypVnlpKSpL3kREREZPZTgBOROWdgcIj7tx7gW4/uZHttGyXRNG44fwnXnl1ORmpSvLsnIiIictwU4ERkznJ3fv9KPd9+dCfP7G4iJ5LMh95YyQfPqSQ3IyXe3RMRERE5ZgpwIjIvbNrbzLcf3clvt9eRnpzIdesquOH8xSzMSY9310REREQmTQFOROaVV+raufnRnfzy+RoSDC5fVcJ71pbzxqX5WvBEREREZjwFOBGZl6qbu/je47u5Z3M1bT0DlOakc9WaMq5ZU0Z5XiTe3RMREREZlwKciMxrPf2DPPRiHXdW7eOJHQ24wzlL8rlmbRmXryohPSUx3l0UERERGaEAJyIS2t/SzT2bqrlzUzWvNXWRmZrE288o4eo15ayuyNHm4CIiIhJ3CnAiImMMDTnP7mnizqpq7ttSS3f/IEsLM7hmbTnvPquUBdlp8e6iiIiIzFMKcCIiR9DRO8BvXqjhzqpqqvY2k5hgXLSikGvWlvOmUxdog3ARERGZVscd4MzsVuBtwEF3XzVO/UXAL4HdYdE97v6lsG4DcBOQCHzP3b8ymc4qwIlIPO2s7+CuTdXcvamag+295GWk8M4zS3nP2WWcWpwd7+6JiIjIPHAiAe4CoAO4/QgB7s/d/W1jyhOBV4BLgGpgI3Cdu794tM4qwInITDAwOMTjrzZw56Z9PPxiHf2DzumlUa5ZW8aVZ5QSjSTHu4siIiIyR00U4JKOdqC7P2ZmlcfxmuuAHe6+K+zAT4ArgaMGOBGRmSApMYGLT13AxacuoKmzj18+t5+fVVXzhV9u4x9/s51LTyviPWvLOXdZAYnaW05ERESmwVED3CSdY2bPAzUEo3HbgFJgX0ybamD9RE9gZjcCNwJUVFRMUbdERKZGXkYKHz53MR8+dzFb97dy16ZqfvHcfn79Qi0l0TSuXlPG1WvKWJSfEe+uioiIyBw2FQFuM7DI3TvM7ArgF8ByYLz/jp5wvqa73wLcAsEUyinol4jISbGqNMqq0ih/fcWp/PbFg9y5aR/f/N0O/vORHaxbnMd71pZzxenFRFKm6v/IRERERAIn/NeFu7fF3L/PzL5lZgUEI27lMU3LCEboRETmhNSkRN76+hLe+voSDrT2cPfmau6s2sef3/k8X/zlVt72+oVcs7aMNYtytbeciIiITIkTDnBmVgzUubub2TogAWgEWoDlZrYY2A9cC7zvRF9PRGQmKo6m8YmLl/GnFy2lam8zd1bt41cv1PDTqn0sKcjg6rVlXLW6jCLtLSciIiInYDKrUN4BXAQUAHXAF4FkAHe/2cw+CXwcGAC6gc+5+5PhsVcA/0GwjcCt7v7lyXRKq1CKyFzQ2TvAfVtqubOqmmf3NJFgcGG4t9ybX7eA1KTEeHdRREREZiht5C0iEke7Gzq5a9M+7t60nwNtPeRGkrnyzFKuWVvGyoXReHdPREREZhgFOBGRGWBwyHliRwM/q9rHw9vq6BscYuXCbN51VimXrSymPC8S7y6KiIjIDKAAJyIyw7R09XHv8zXcWVXNlv2tAKxcmM2GlcVsWFXMsgWZWvxERERknlKAExGZwV5r7OLBbQd4YNsBNu1tBmBJYQaXrSxmw8piXl8WVZgTERGZRxTgRERmibq2Hh56sY4Htx7gqV2NDA45C6NpXLqymMtWFnN2ZS5JiQnx7qaIiIicRApwIiKzUEtXH/+z/SAPbDvAY6/U0zswRF5GCpe8rogNq4p547J8rWYpIiIyBynAiYjMcl19A/z+5Xoe2HaAR7YfpL13gMzUJC4+dQEbVhZz0SmFZKSe8PaeIiIiMgNMFOD0m15EZJaIpCRx+eklXH56Cb0Dgzy5s5GHth3goW11/Or5GlKSErhgeQGXrSzmLa8rIjcjJd5dFhERkSmmETgRkVlucMip2tPEA9sO8ODWA9S09pCYYLxhSR6XrSzm0tOKKY6mxbubIiIicgw0hVJEZB5wd7bub+OBbbU8sPUAO+s7ATirIocN4SIolQUZce6liIiIHI0CnIjIPLTjYDsPbqvjga0HRvaaO7U4K9ieYFUxpxZnaXsCERGRGUgBTkRknqtu7uLBbcH2BBv3NuEOFXkRNqwKRubOKs8hIUFhTkREZCZQgBMRkRH17b38dnswMvfkzgb6B50FWalcurKIDStLWL8kj2TtNSciIhI3CnAiIjKutp5+fvfSQR7YeoBHX66nu3+QaHoyb3ldEZetLOKCFYWkJWuvORERkemkACciIkfV3TfIY6/W8+C2A/z2xTraegaIpCRy7rICzl9ewHnLClhckKHr5kRERE4y7QMnIiJHlZ6SyGXhapX9g0M8vatxZGTu4RfrACjNSefcZfmct7yQc5fmk5+ZGudei4iIzB8KcCIiMq7kxATOX17I+csLcXf2Nnbx+I4G/vBqAw9sPcDPqqoBOK0km/OXF3DusgLWLc7TdEsREZGTSFMoRUTkmA0OOVv2t/LEq/U8/moDm19rpn/QSUlK4OzK3GDK5bJCVi7M1sqWIiIix+G4r4Ezs1uBtwEH3X3VOPXXA38VPuwAPu7uz4d1e4B2YBAYGK8D41GAExGZXbr6BnhmdxN/eLWBJ3Y08NKBdgByIsmcu7SA88Lr58rzInHuqYiIyOxwItfA3QZ8A7h9gvrdwIXu3mxmlwO3AOtj6i9294Zj7K+IiMwikZQkLj5lARefsgCAg+09PLmjkcdfbeCJHfX8ZkstAIvyI5y3LAhzb1xaQDSSHM9ui4iIzDqTmkJpZpXAr8cbgRvTLhfY6u6l4eM9wNpjDXAagRMRmTvcnZ31HTz+agN/2NHAUzsb6ewbJMHg9NJoODpXyOpFOaQm6fo5EREROMFtBI4hwP05cKq73xA+3g00Aw58x91vOcKxNwI3AlRUVKzZu3fvUfslIiKzT//gEM/vawlH5xp4bl8Lg0NOenIi6xbnBSN0yws4tThL2xWIiMi8ddIDnJldDHwLOM/dG8Oyhe5eY2YLgIeBT7n7Y0d7PY3AiYjMH+09/Ty9q4k/7Gjg8Vfr2VnfCUBBZgrnhtMtz1teQEk0Pc49FRERmT4ndR84M3s98D3g8uHwBuDuNeHtQTP7ObAOOGqAExGR+SMrLZlLTiviktOKAKht7eaJcHTuDzsa+OVzNQAsLczg/OWFnLusgDcsySMrTdfPiYjI/HPCAc7MKoB7gA+4+ysx5RlAgru3h/cvBb50oq8nIiJzW0k0nWvWlnPN2nLcnZcOtI8Eup9sfI3bntxDYoJxZnkO5y0r4PzlBZxRnkNyYkK8uy4iInLSTWYbgTuAi4ACoA74IpAM4O43m9n3gKuA4YvWBtx9rZktAX4eliUBP3b3L0+mU5pCKSIi4+kdGGTz3hae2FHPEzsa2VLdwpBDalICp5Zks2phNqeXRllVGmVFURYpSQp1IiIyO53QNXDTTQFOREQmo7Wrnyd3BhuJb9nfyrb9bbT3DgCQkpjAKcVZrCrNZlVplFULo5xSnEVasla6FBGRmU8BTkRE5ryhIee1pi621rSOBLot+1tp7e4HICnBWFEUhLrTS6OsLI1yWkm2Qp2IiMw4CnAiIjIvuTvVzd1s3R+Euq01bWzd30pTZx8AiQnGssLMYJQuDHanLcwmkjIl63yJiIgcl5O6CqWIiMhMZWaU50Uoz4tw+eklQBDqalt7wlG6INj9/pV67t5cHR4DSwszg1G6hYdCnVa+FBGReFOAExGRecfMWJiTzsKcdC5bWTxSXtfWw5bqVrbWtLJ1fytP7Wzk5/+7f6R+SUEGK0ujnB5eV7dyYZRoukKdiIhMHwU4ERGRUFF2GkWnpfGWcE86gPr23iDQhcFu895mfvV8zUj9ovwIqxZGR6ZgrloYJTcjJR7dFxGReUABTkRE5AgKs1K5+JQFXHzKgpGyxo5ettUEC6Rsq2nlhf0t/GZL7Uh9WW46qxZGOb0smIK5cmGUgswUzCweb0FEROYQBTgREZFjlJ+ZygUrCrlgReFIWWtX/8jUyyDYtfHAtgMj9XkZKawoyuSUoixWFGdxSlEWy4uyNAVTRESOiQKciIjIFIhGkjl3WQHnLisYKWvr6Wfb/jZeOtDGK3XtvHygnbs376cj3KsOoCSaxoqiLFYUZbKiKItTirNYviCL9BRtbSAiIodTgBMRETlJstOSOWdpPucszR8pc3dqWnt45UA7L9e1j9w+tauRvoEhIFgFsyIvEgS6mBG7xQUZpCQlxOvtiIjIDKAAJyIiMo3MjNKcdEpz0rn41EPX1Q2Gm5C/fKA9GK0Lw90jLx1kcCjYszUpwVhSmDEq2K0oyqIiL0Jigq6vExGZDxTgREREZoDEBGNxQQaLCzLYsOrQ1ga9A4Psbug8FOwOdPBCdSu/fuHQoimpSQksH56CGTNiVxJN08IpIiJzjAKciIjIDJaalMipxdmcWpw9qryrb4BX6zp4pW54xK6DJ3c0cs/mQzySkQAAACAASURBVPvWZaUmjYzSnVKUORLs8jNTp/ttiIjIFFGAExERmYUiKUmcUZ7DGeU5o8pbu/p55WB7zIhdOw9sreWOZ/tH2uRnpIwsmLKiKIulhRmU50Uoyk7TVEwRkRlOAU5ERGQOiUaSObsyj7Mr80bK3J36jl5eresYdY3dnVX76OwbHGmXnGgszEmnLDedspxIcJuXTlluhPLcCAuyUklQwBMRiSsFOBERkTnOzFiQlcaCrLRR2xy4O/tbutlV30l1czfVzV0jt797+SAH23tHPU9yYrAAS1luGO5yw3AXhrzCTAU8EZGTTQFORERknjKzMIxFxq3v6R9kf0v3mHDXzb6mLn67/SANHaMDXkpiAqUjwS426EUoz02nQAFPROSEKcCJiIjIuNKSE1lamMnSwsxx67v7hgNeF/vGhLyHX6yjoaNvVPuUpATKctIpzU2nPC8yJuSlU5iZqlUzRUSOQgFOREREjkt6SiLLFmSybMH4Aa+rb4D9zeOM4DV3sW3rAZo6Rwe81KRgBK88d3S4K8+LsCgvQk4kWQFPROa9SQU4M7sVeBtw0N1XjVNvwE3AFUAX8CF33xzWfRD427DpP7r7D6ai4yIiIjKzRVKSWF6UxfKirHHrO3sHRkbwhqdmDoe8F6pbaO7qH9U+Oy2JRfkZLMqPUJmfQUV4uyg/WGBF4U5E5oPJjsDdBnwDuH2C+suB5eHXeuDbwHozywO+CKwFHNhkZve6e/OJdFpERERmv4zUJFYUBVsZjKejNxjB29vYyWtNXext7GJPYydb9rdy/9YDDA75SNv05EQq8iJBuCvIoCLvULgriaaRlJgwXW9LROSkmlSAc/fHzKzyCE2uBG53dweeNrMcMysBLgIedvcmADN7GNgA3HEinRYREZG5LzM1iVOKg/3qxuofHArCXVMXexs72dsY3O5u6OTRV+rpGxgaaZucGCzWMjJylxehsiBCRV4G5XnppCYlTufbEhE5IVN1DVwpsC/mcXVYNlH5YczsRuBGgIqKiinqloiIiMxFyYkJVBZkUFmQARSOqhsacurae9jTEIa7mJBXtaeZjt6BkbZmsDCazqL8SPiVQWV+EO4W5UfISNVyASIys0zVT6XxJp37EcoPL3S/BbgFYO3ateO2ERERETmahASjJJpOSTSdc5bmj6pzdxo7+0ZG7EZum7p4cFvdYQurFGSmBoEu5nq74ZCXE0mZzrclIgJMXYCrBspjHpcBNWH5RWPKH52i1xQRERE5JmZGQWYqBZmprFmUe1h9W08/r4XX2sWGvCd3NHLP5v2j2manJVFZkEF5boTCrNRRXwvC2/yMVBK1952ITKGpCnD3Ap80s58QLGLS6u61ZvYg8E9mNvwT8lLgr6foNUVERESmVHZaMqtKo6wqjR5W1903yL7mLvY0BIuqDIe87bVtPPZKL+0xUzOHJRjkZRwKdGMDXmHmobLM1CStpCkiRzXZbQTuIBhJKzCzaoKVJZMB3P1m4D6CLQR2EGwj8OGwrsnM/gHYGD7Vl4YXNBERERGZTdJTEo+4amZ33yD17b3Ud/QEt+29HAxvg/JeXj7QTkNHLwNDh18tkp6ceCjkZaayIHt0wAuCXxr5mSkka1VNkXnLgoUjZ5a1a9d6VVVVvLshIiIiMuWGhpyW7v4w4B0Ke6MCX0dw29rdP+5z5GWkTBjyRkb4MtPITteonshsZWab3H3t2HItrSQiIiIyjRISjLyMFPIyUsbdIiFWT/8gDR2jR/EOth0KePXtveyq76S+vZe+waHDjk9JSqAwM5WSaBrF0TQW5qRTnJ028rgkmk5hlq7TE5lNFOBEREREZqi05ETKciOU5UaO2M7daeseoL6j57CAV9fWQ21rD1v2t/LQi3Wj9sgDSEwwirJSRwJdcJs2clsSTWdBVqo2QxeZIRTgRERERGY5MyMaSSYaSWbZgolH9dyd5q5+alu7OdAaBLva1m5qW3s40NrD9to2/uelOnr6R4e8BIPCrFSKo+mUZMeEu5z0IOxlp1GUnUZKkkKeyMmmACciIiIyT5gdmr65cuHhK23CodG82rZDwa62Jbzf1sOO+g4ef7Wezr7Bw44tiJ2uGU0LAl/MaF5RdhppyYkn+22KzGkKcCIiIiIyInY079Ti7Anbtff0jzuKV9vaw2uNXTyzq5G2nsO3VsjLSAmnZgbBrjg7jYLMVPIzUynITBnZpy89RUFPZDwKcCIiIiJyzLLSkslKS2b5BNsqAHT2DnCgLQh2NS3htM3w8f6WHjbtbaa5a/yVNiMpiWGwOxTqhgPeobLgNpqerNU2Zd5QgBMRERGRkyIjNYmlhZksLcycsE1P/yCNnX00dvTS0NFLQ0cfDR29NMbc7mvq4n9fa6aps49xttAjKcHIz0whPyOVgqxUCjJSKMhKJT9jdOArzEolL0P76MnspgAnIiIiInGTlpxIaU46pTnpR207OOQ0d/WNhLvhwDcc/obLdx7soL6j97AVN4flRJJHwt3wSF5+eH/s6F4kJVGjezKjKMCJiIiIyKyQmGAjoesUjryHnrvT0TsQE/bGjOx19tLQ3sf2A200tPeOe70eQFpyAvkZqeRmJJMbCRaAyY2kkJ+RQm5GzOPM4DYnkqwRPjmpFOBEREREZM4xs5Hr9CoLMo7avndgkKbOPhra+2jo7KWhvZfGzj4a2ntp7uqnqbOXpq5+9jZ20dzZR3vv+IEPIDstaWS1z+GAlxcT+PIio+9npydplE8mTQFOREREROa91KRESqLplESPPpUToG9giOauPpo6+2ju7KOpK7htHHncT3NnHzUtPWzd30ZTV9+EUzoTEywMeYdG+cYLfyOjfpEUrdI5jynAiYiIiIgco5SkBIrCDcwnw93p6gtG+Zq7YoJe+LipMxjla+7s59WDHTSH5eMt2gLB1M7hkbzcSArRSDI56cnkRIIQGE1PJiec0pmTnhzWp2iz9TlAAU5ERERE5CQzMzJSk8hITaI8LzKpY4aGnNbu/pHRvbFhr6mzn+auPlq6+qhp7aa1q5+W7n4GJ0p9QEZKIjkjAW/4K2Uk/OWkB2Ewd0z4S03SiN9MoQAnIiIiIjIDJSRYMMKWkQKFkzvG3WnvHQjCXFc/Ld19wW1XeNsdlLd299Hc1c/LB9ppDcsGjhD80pMTDw97kWSi6SnhqN+h+8NBMCeSTFqygt9UU4ATEREREZkjzIzstGSy05Ipz5v8ce5OZ9/goaAXE/5au4Pr+WLD346DHeHjPvoHJw5+w6t4FmSlUjh2U/as1JHHhZmpWsxlkhTgRERERETmOTMjMzWJzNQkynInf9zwtX3DYW54GmdzGASHF3Zp6Oilurmb5/a10tTZO+61fSmJCYftwze8IXthTNgrCLdsSEiYn2FPAU5ERERERI5L7LV9k9mMHYIN2Vu6+kb25mvo6KW+vXf0445ette209jZO+4IX2KCkZdxKOwVhmGvYNQoXyoFWcGqnUlzaG++SQU4M9sA3AQkAt9z96+Mqf934OLwYQRY4O45Yd0gsCWse83d3zEVHRcRERERkdknMcHIz0wlf5Ibsrd294ch71DAa+gINmJv6OilobOPXfWdNHT00jvOVg1mkBdJGQl0owJeZgrnLy+kODq51URngqMGODNLBL4JXAJUAxvN7F53f3G4jbt/Nqb9p4CzYp6i293PnLoui4iIiIjIfGBm4XYIKSxbcOS27k5H78Chkbz24dG80Y//97UWGjp66eobBOD2j6ybWwEOWAfscPddAGb2E+BK4MUJ2l8HfHFquiciIiIiInJ0ZkZWWjJZacksLsg4avuuvgEa2vsoyEqZht5NnclMBi0F9sU8rg7LDmNmi4DFwCMxxWlmVmVmT5vZOyd6ETO7MWxXVV9fP4luiYiIiIiIHJ9IShIV+REiKbNrWZDJBLjxlneZaK3Qa4G73H0wpqzC3dcC7wP+w8yWjnegu9/i7mvdfW1h4SQ3uhAREREREZlHJhPgqoHymMdlQM0Eba8F7ogtcPea8HYX8Cijr48TERERERGRSZpMgNsILDezxWaWQhDS7h3byMxOAXKBp2LKcs0sNbxfAJzLxNfOiYiIiIiIyBEcdcKnuw+Y2SeBBwm2EbjV3beZ2ZeAKncfDnPXAT9x99jpla8DvmNmQwRh8Suxq1eKiIiIiIjI5NnovDUzrF271quqquLdDRERERERkbgws03hWiKjy2digDOzemBvvPsxjgKgId6dkBE6HzOLzsfMovMxs+h8zCw6HzOLzsfMovMxcyxy98NWd5yRAW6mMrOq8VKwxIfOx8yi8zGz6HzMLDofM4vOx8yi8zGz6HzMfJNZxERERERERERmAAU4ERERERGRWUIB7tjcEu8OyCg6HzOLzsfMovMxs+h8zCw6HzOLzsfMovMxw+kaOBERERERkVlCI3AiIiIiIiKzhAKciIiIiIjILKEAN4aZbTCzl81sh5n9n3HqU83sp2H9M2ZWOf29nB/MrNzMfmdm281sm5l9epw2F5lZq5k9F359IR59nU/MbI+ZbQm/31Xj1JuZfT38jLxgZqvj0c/5wMxOifm3/5yZtZnZZ8a00WfkJDKzW83soJltjSnLM7OHzezV8DZ3gmM/GLZ51cw+OH29nrsmOB//YmYvhT+Pfm5mORMce8SfbXLsJjgff29m+2N+Jl0xwbFH/HtMjt0E5+OnMedij5k9N8Gx+nzMILoGLoaZJQKvAJcA1cBG4Dp3fzGmzZ8Cr3f3j5nZtcC73P29cenwHGdmJUCJu282syxgE/DOMefjIuDP3f1tcermvGNme4C17j7uJp/hL+NPAVcA64Gb3H399PVwfgp/fu0H1rv73pjyi9Bn5KQxswuADuB2d18Vln0VaHL3r4R/eOa6+1+NOS4PqALWAk7w822NuzdP6xuYYyY4H5cCj7j7gJn9/wBjz0fYbg9H+Nkmx26C8/H3QIe7/+sRjjvq32Ny7MY7H2Pq/w1odfcvjVO3B30+ZgyNwI22Dtjh7rvcvQ/4CXDlmDZXAj8I798FvNnMbBr7OG+4e627bw7vtwPbgdL49kom4UqCXw7u7k8DOWEYl5PrzcDO2PAmJ5+7PwY0jSmO/T3xA+Cd4xx6GfCwuzeFoe1hYMNJ6+g8Md75cPeH3H0gfPg0UDbtHZunJvh8TMZk/h6TY3Sk8xH+Lfse4I5p7ZQcFwW40UqBfTGPqzk8MIy0CX8htAL509K7eSycqnoW8Mw41eeY2fNmdr+ZrZzWjs1PDjxkZpvM7MZx6ifzOZKpdy0T/+LVZ2R6Fbl7LQT/EQUsGKeNPifx8RHg/gnqjvazTabOJ8MprbdOMMVYn4/pdz5Q5+6vTlCvz8cMogA32ngjaWPnmE6mjUwhM8sE7gY+4+5tY6o3A4vc/QzgP4FfTHf/5qFz3X01cDnwiXBKRix9RqaZmaUA7wDuHKdan5GZSZ+TaWZm/x8wAPxogiZH+9kmU+PbwFLgTKAW+Ldx2ujzMf2u48ijb/p8zCAKcKNVA+Uxj8uAmonamFkSEOX4pgfIJJhZMkF4+5G73zO23t3b3L0jvH8fkGxmBdPczXnF3WvC24PAzwmmusSazOdIptblwGZ3rxtboc9IXNQNTxsObw+O00afk2kULhLzNuB6n+Di/0n8bJMp4O517j7o7kPAdxn/+6zPxzQK/559N/DTidro8zGzKMCNthFYbmaLw//Rvha4d0ybe4Hh1cKuJrgwWv8rdBKE87G/D2x3969N0KZ4+BpEM1tH8G+6cfp6Ob+YWUa4oAxmlgFcCmwd0+xe4I8s8AaCC6Jrp7mr882E/3Oqz0hcxP6e+CDwy3HaPAhcama54RSyS8MymWJmtgH4K+Ad7t41QZvJ/GyTKTDmmuh3Mf73eTJ/j8nUeQvwkrtXj1epz8fMkxTvDswk4QpVnyT4JZoI3Oru28zsS0CVu99LECh+aGY7CEbero1fj+e8c4EPAFtilrX9G6ACwN1vJgjRHzezAaAbuFaB+qQqAn4e5oEk4Mfu/oCZfQxGzsl9BCtQ7gC6gA/Hqa/zgplFCFZq+5OYstjzoc/ISWRmdwAXAQVmVg18EfgK8DMz+yjwGnBN2HYt8DF3v8Hdm8zsHwj+UAX4krtrNscJmuB8/DWQCjwc/ux6OlxJeiHwPXe/ggl+tsXhLcwpE5yPi8zsTIIpkXsIf3bFno+J/h6Lw1uYU8Y7H+7+fca5hlqfj5lN2wiIiIiIiIjMEppCKSIiIiIiMksowImIiIiIiMwSCnAiIiIiIiKzhAKciIgcMzNLNLMOM6uY5te9wcwenUwfYtse52s9ZGbXH+/xIiIiJ4MCnIjIPBAGneGvITPrjnl8zCEl3Mcp091fO4Y+XGBmjx3ra01lHyZiZv9oZreNef5L3X2iTZ9FRETiQtsIiIjMA+6eOXzfzPYAN7j7bydqb2ZJ7j4wxd24gmCbCYmjk3RuRURkmmgETkREhkegfmpmd5hZO/B+MzvHzJ42sxYzqzWzr5tZctg+yczczCrDx/8d1t9vZu1m9pSZLR7zMlcA95nZ98zsK2Ne/zdm9mfh/b81s13h82wzs3dM0OexfSg0s1+bWZuZPQ0sHtP+G2ZWHdZvNLM3huVvA/4SuD4ckdwUlj9hZh8K7yeY2RfMbK+ZHTSz28wsO6xbFvbjj8Lnrzez/3OE7/U7zOy58P29ZmZ/N6b+gvD73mpm+8zsA2F5xMz+PTym1cweM7NUM3tLGMpjn6PazC46nnMbHnO6mf3WzJrM7ICZ/aWZlZpZl5nlxLRbH9brP4RFRKaJApyIiAx7F/BjIAr8FBgAPg0UAOcCG4jZMHwc7wP+Dsgj2MD6H4YrzKwMyHH3F8LXuNYs2BXWzPKBN4WvCfBK+HpR4MvAj82saBL9/zbQDhQDNwIfGVP/DPD6sH93AXeaWaq7/xr4KvCjcErmmnGe+wbg/QSb4C4FcoGbxrR5I7AMuAz4v2a2fIJ+doTPFQXeDnw6DJGEofc3wNeAfOAsYEt43L+H/V8fvoe/AYYm/naMMulza2ZR4LfAr4ASYAXwqLvvB54g3Jg89H7gDo3oiYhMHwU4EREZ9oS7/8rdh9y92903uvsz7j7g7ruAW4ALj3D8Xe5e5e79wI+AM2Pq3grcH95/FEgGzgkfvwd43N3rANz9Z+5eG/bjx8AeYO2ROh6OHr0T+Dt37wqD4g9j27j7D929KQwbXwWyCQLXZFwP/Ku773b3doLw9D4zi/09+vfu3uPum4FtwBnjPZG7P+LuW8P39zzwEw59X98PPBB+DwbcvcHdnzOzROBDwJ+F35tBd38i/F5PxrGc23cA+9z9Jnfvdfc2d382rPtB2EfCUbf3Mub7LCIiJ5cCnIiIDNsX+8DMTg2nNh4wszbgSwQjNhM5EHO/C8iMeTxy/Zu7DxGMAl0X1r2PIPANv+6HzOz5cHpfC3DqUV4XoAhIHPMe9o55P39pZi+ZWSvQDGRM4nmHLRzzfHuBFKBwuMDdj/T+Y/txjpk9Gk61bCUY3RvuRzmwc5zDisLXG69uMo7l3JYDOyZ4np8DZ1iw8ucGoD4MrCIiMk0U4EREZJiPefwdYCuwzN2zgS8AdqxPamapBNP0YhdNuQN4TzhlcDVBMMDMlhBMhfw4kO/uOcBLk3jdOoLphOUxZSPbC5jZxcDngKuAHIIpkB0xzzv2vY9VAywa89x9QP1RjhvPT4C7gXJ3jwLfi+nHPoIpmmPVha83Xl0nEBl+EI6M5Y9pcyzndqI+4O5dYd+vBz6ARt9ERKadApyIiEwkC2gFOs3sdRz5+rcjuRDY7O6dwwXuvjF87luA+9y9LazKJAgb9YCZ2Q0EI3BHFE4l/AXBtWfpZraKIGDEvpcBoIFg+ubfE4zADasDKoevyxvHHcDnzKzSzLIIrs27IxxNPFZZQJO795jZG4BrY+r+G9hgZleFi7QUmNkZ7j4I3Ab8h5kVW7AH3rnh1NGXgCwzuyx8/MXwPR6tDxOd23uBCjP7pJmlmFm2ma2Lqb+d4PrCt4b9FRGRaaQAJyIiE/k88EGChUG+w6FFRo7VRNsH3AG8hWBxDQDCa9e+DjwL1BKEt2cm+TofJxhZqwO+D/xXTN19BCOArxJcU9cWPv+wnxJMUWwys2c53HfDNo8Duwi+J5+eZL/G6+c/hytC/g3ws+EKd99NsLDJXwFNwGbg9LD6s8B2YFNY90+AuXsz8CmC69P2h3Wx0znHM+G5dfdW4BKC0cqDBIvKxF77+BjBdNVn3L362N66iIicKHM/2qwRERGR42dmrwBvc/dX4t0XmRoWbMh+q7vfFu++iIjMNxqBExGRk8bM0oDvK7zNHeG0z1XAnfHui4jIfKQROBEREZkUM/sRwbVvn3J3LWAiIhIHCnAiIiIiIiKzhKZQioiIiIiIzBJJJ3KwmW0AbiJYjep77v6VMfUVBKti5YRt/o+7j7cS2SgFBQVeWVl5Il0TERERERGZtTZt2tTg7oVjy487wJlZIvBNgqWGq4GNZnavu78Y0+xvgZ+5+7fN7DSCZZwrj/bclZWVVFVVHW/XREREREREZjUz2zte+YlMoVwH7HD3Xe7eB/wEuHJMGweyw/tRoOYEXk9ERERERGReO5EAVwrsi3lcHZbF+nvg/WZWTTD69qmJnszMbjSzKjOrqq+vP4FuiYiIiIiIzE0nEuBsnLKxS1peB9zm7mXAFcAPzWzc13T3W9x9rbuvLSw8bKqniIiIiIjIvHciAa4aKI95XMbhUyQ/CvwMwN2fAtKAghN4TRERERERkXnrRALcRmC5mS02sxTgWuDeMW1eA94MYGavIwhwmh8pIiIiIiLTzt0ZGByid2CQrr4B2nv66R8cine3jslxr0Lp7gNm9kngQYItAm51921m9iWgyt3vBT4PfNfMPkswvfJDrp3DRURERETmHHenpaufmtZualt6qG3tpr69l75BZ3BoiMEhglv3Q/dHyoYf+wRlMV+jjo8pGzxCXXh/aJwk8oOPrOPCFbPnEq4T2gcu3NPtvjFlX4i5/yJw7om8hoiIiIiIxF97Tz+1rT3UtHRT29pDbUs3Na1BUKtt6aGmtZue/tGjWWaQnJhAohmJCWO+JluWYCQlJJCaNE7bxDHHjFd2hOdOSjCWFGTE6Tt6fE4owImIiIiIyOzX0z84EsxGAlprNzUthwJae+/AqGPMYEFWKiXRdE4tyeLiUxdQEk1jYU76yG1BZiqJCeOtfSjHSwFORERERGQO6xsYoq7tUDCLneI4HNCau/oPOy4/I4WSnDQW5WdwzpJ8SmKCWUk0jaLsNJITT2RJDTkeCnAiIiIiIrPU4JBzsL1n1EjZqIDW2kNDRy9jV6HITvt/7d15eFvVgffx75G8744dO47XLCb7RpyEnRB2WggFygDdaYehA2U6XaZvO13pvFNoO21pS0vTAF3eUqB7GNZQdmggzgbZnTh2YsexE9uxLe+SzvvHlW3ZsbPJsWT793kePdK990g68rVk/Xy2qN4gtrAgjcmpceSkxpOTFsfk1HgmpcYRF+0Oz4uS41KAExEREREJ8Pst1UfbKatroazWw4HGNrw+iz8wOYa1zqQYfuuU9du+yTH8tm/bWgL7ey4E9gfu7x+kfE/ZwLGTeVxvYF+whBh3b0vZjEnJ5KTGMzktrt91YqxiwGilMyciIiIi447PbznQ0EZZnac3rJXVtbCnztNvIo70hGhioly4jHEuLnD33ja4DL3H3D3brsC2MRgDUS4Xbpdz2x045lyCtgP3de5jcLsYYn/Qc7oM0S5DVkpcX0BLjSclPgpjNO5srFKAExEREZExy+vzU9nQRlmthz11Leyu9VBW52HvYQ9d3r6gNjk1junZyXxoWQbFWUkUZycxfWIyqQnRYay9yLEU4ERERERk1Ovy+qmsb3Va1Go97K5rYU+th31HWukKWqg5Lz2e4qwkLizOZHpWEsVZSUzPSiI5TkFNRgcFOBEREZExxu+3VDU647hqmztJjHWTEh9NSlwUKXHRJMdFkxIfRXy0e9R1tev0+th3pDXQ5dFDWW0LZXUeKo604g2s0mwMFExIoDgriUtmZvW2qE2bmKSxXzLq6TdYREREZJTy+S37G9p6Q0zP9d7DnmMWVB6M22VIiYsiOS6a5N5wF0VK/LHbA8Nfz33O1DTyHd0+9h72sKfOw+7alkAXSA8V9a0EchouA0UZiUzPSuLKOdkUZyUzPdCiphkUZaxSgBMRERGJcN0+P5X1QUEtENbKj7QOOo7rnKk947iSyUmNo63LS3OHl+b2blo6vDR3BK4D2y0d3TQHrivr23q3PQMWbh5MfLR7yNDXs50StJ0cF92vjAHKD7dSFhiftqfOeY37G9p6Z1eMchmKMhOZMSmZ98/PYXp2MsVZSUzJTFRQk3FHAU5EREQkQnR5/VTUt/ZrcSqra2HfkVa6fX1zxfeM47rorIm9QW3axMRhH8fl81s8nUMFv77QF3zsaFsXBxraaA4cDw6YJxLtNkzNTGJubiofWJRLcVYyxdlJFGUkEhOlBaNFQAFOREREZMR1dDvjuHbXOtPW90xhX1Hfhu+YcVzJXDor2wlqWclMy0okIWZkvsK5XYbU+GhS408/GHZ0+45p5Wtu79nuxuu3TM1MZHpWMoUZCWesS6aMoPajULcD6rZBwz6IjofYZIhJgtgU53ZsUuA62dkXkwRRsc4vvhyXApyIiIjIGdLe5Yzj6ltnzGlVqwwax+V2GQoznAk3rp6b40xfn+VMuDEWugfGRbuJi3YzMTk23FWR4dbdAUd2OWGtdlsgtG2H5uq+MlFx4OsCexItsa7ooFAXdIkZEPaCw1/MwPJJzj732I05Y/eViYiIiIyQ1k4vew97AmuMOdPXl9V5ONDYfxzXlMxEZuUkc+2Cyb0zI07JTCQ2avQHtTHD74fGfVCzW9rG4AAAIABJREFUxbkc3Q/JOZBeCGmFkFbgXGKTwl3TkeP3QWOFE85qtzsta3U7oH4vWJ9Txh0DmTOg8HzIng1ZcyBrFqTmOce726DTA50t0NnsXHf1bPfsC95uga4WaD0MDeV9x7pbT67O0QmDhL/BgmEKzLjKOaejhAKciIiISIC1zpivpvbu3ktzuzPmq9++jr7bdc2dVB9t732MGLeLqRMTmZ+Xyo1n51Gc7aw1VpSZqO6BkcbnhfqyvrBWswUOveeECXBahFJzoaUWvO3975uQ4QS69J5QV9gX8lLzITpu5F9PqKwFT23/1rS67VC3M+j1G0gvguw5MHslZM12bk+YCu7jdLWNSXQuydmh1dHvO3H46/L0hcTOlr5jRw84+7s80NEM/m7nMTOnK8CJiIiIhIvPb2keELJ6glj/7cHKdPd2bRyMyxCYUj+6d2zYkqIEbs3KpzgwM2LBhASiRjqoWQttDXC0wmkxaqyEo5XO7Y5mmDAFMqZDxjSYMM25jk0e2TqGm7fTCSM17/aFtdqt4O1wjkfFw6S5MP9myFkAk+Y7LUhRsc7Pt/Vw0M+1su/nXLMFdvxvXxjokTSpf6tdcNBLzTt+2BkJHc1949TqdgRa1rZDe0NfmcQspzWt5HbnZ5E9GybOdIJYuLjcEJ/mXELl7XTC3ShrTTXWHudTKkxKSkpsaWlpuKshIiIiYeT3W+paOjnY1N4broKvBwtnze3dtJxg6vtotzMxR0oggAWHMWd/VNDtoOMJ0STFROFyhWmShY6mQIDY7wSI4NtH9zutCsHi052wEJvsdH9rOtD/eNKkQKibGrgOXNKLnNAymnW1wqGtcOhdqNnshKy6HeAP/G7EpjgBLWdB3yVj+umPm/L7oaVmiHNTCU3VfV0NAYwLUnIHhLug28k5TlAZDt5OOFLW15rWE9SCfx9ikpyAljU70KIWuE7MHJ46yGkxxmyw1pYcs18BTkRERMLF77fUtnSw70grlfVtVBxppaI+cLu+dcjFqOOj3ccPW0H7Ugdc4qJdmEic6a6rNaj1LOjLf0+rT0dT//IxyYN03yvoCwJxKf3Ld7c7MwLW7wlc9kLDXud26+G+csbldAHsDXWBFruM6c7+4QoWw6X9aCCobelrXasv65s0IyEDchZCTlBgSysC1wi2kvq6nYk9BraO9pzrlhog6Du5K9pppesX7oK6aCZlHTtbo9/vPG5wSKvb7pzfnuDqioLMswJBbZbT9TFrduC8qntvpDkjAc4YcxXwAOAGVltr7xtw/IfAJYHNBCDLWnvC9k4FOBERkbHD77ccau4IhLM2KutbewNbZUP/kBbjdlGQkUBRRgJFGYkUZiaSlxZPakJfOEuJjxqdk354O50xOIN1c2yshLYj/ctHxfdNmHFMV7xCp4VtuIJo+9FAmOu5BIW8rpa+cu4YSA/qjhl8nZR95qeA9xwOBLXNfaGtsaLveEpuX/fHnrCWMjnyp6bv/d0YGO4Ct4MDNjgzO/b8biRkOOeqbmf/CT7SCpyJRHpa07JmO+cpKmZkX5uctmEPcMYYN7AbuByoAtYDt1prtw9R/jPAImvt7Sd6bAU4ERGR0cXvt9T0hjQnnDkhzbndGbSYc0yUi8IJCRRmJDIls+c6kcKMBHJS43GHq4tiqHpaWYbq5thS07+8KxrS8gfpRhdoaUmcGP7g0TP2qzfQ7ekLeQ3l4OvsKxuTFDTGLqhLZsZUJ2ye6vM2V/efXKTmXWg52FcmfUpQF8j5MGkBJE0cntcdabpa+wLewHF4rUecCUSyA7M+Zs2BrJnjb4zjGDRUgAtlEpOlwB5rbXngCR4HVgKDBjjgVuAbITyfiIiIhJHPb6lpaqfiSFsgpLWy74jTolbZ0EZXUEiLjXJRmOGEs+UzsijMSGBKoEUtJyUufOPIglnrTGDR3e5Mcd7V5lx3tzstGd3tQxwLut3V2jc2rXmwcU55ThibtuLYoJY8KfK6Iw5kjNNdLykLCs/rf8zvg6YqJ9Q1lPcFvIMbYftf+6/7lZDhhLkJQd0xM6Y7wSMqrv+0/TVbnNa1tvpAHVxOt78pF/YFtknzIC515H4O4RaT6ISyrJnhrolEgFACXC4QPBq2Clg2WEFjTCEwBXhpqAczxtwB3AFQUDB6pvEUEREZS3x+y8Gj7U4LWn0rlYEWtYr6NvYPEtKKAq1nK2ZmUZiRSFGm0/Vx0nCFtO4OZ1a8ocJVV+uxoSo4XPWGsNYBYSxwm1PsiWRcEJ0I0fEQkxBYayoFCs45djxaSm74Zxo8k1xu53WmFwKX9j/m7XRCbXDLXUM5lL8MWx7rXzYqvm+Kele00+VvxjWBsLbQaVmKSRiRlyQyGoQS4Ab7VB7qU/AW4I/WBv9basAdrV0FrAKnC2UI9RIREZET6PL6KatrYWt1E7trPb1dHw80tNPl6wtpcdFOSJs2MZFLZ2VRlJHoXDITyE4OIaR5O6HlkLPmVEuNc7ulxllvq2fbcwjaG0/hQY0TqGISnIAVndB3ScjsC1z9jsUH3WeQYzGBsBYd7wQ3d3T4uzWOBlGxMPEs5zJQp6f/eLv2BqfrX84CmDhLY7RETiCUAFcF5Adt5wEHhyh7C3BXCM8lIiIip6nT62P3IQ/vVTfxXnUT2w42sbOmpTeoxUe7KcxIoDgrmctnT3ImEMl0glp2Suypzdjo7QqEskP9g9jAgBa81lQPV5QztX3yJKebXdH5zu2EzECQOkHgiopVuBoNYpP6ukKKyCkLJcCtB4qNMVOAapyQdtvAQsaYGUA68I8QnktEREROQke3jx01zWw92MzWqia2Hmxid20L3T6nc0tKXBTz8lL5xPlFzM1NZW5uKoUTEk7ckubrPjaY9VyCA1rPuKVgxu0EseRJzhpjBec461z17Eue5GzHT9BU5iIiJ3DaAc5a6zXG3A08j7OMwCPW2m3GmHuBUmvtmkDRW4HHbSQuOCciIjKKtXV52VHTzHtVTU5gq26irM6Dz+/8yU1PiGZubiqfunAq83JTmTs5lfwJ8f1b1Px+Z2a/fq1khwZcao6d4h6cYJaU5QSwtALIX9rXghYc0BIyFcxERIaJFvIWEREZBTydXrZV9wW1rdVN7D3sIZDVyEyKcVrUJjutavPyUpmcGnds98dOD1RvgAPvwIG3oeqdYxeINi5IzDq2hSx5Uv+AlpgZ+bMoioiMUmdiGQERERE5A5rau9l2sIlt1c28V+10g9x3pJWe/7lmJccyLzeVa+blOGEtN3XosWpHDzhBredyaGvfVPcTZ8Hs6501tFJy+4JZQia49RVBRCQS6dNZREQkjI62dbE1KKhtrW6isr6t9/jk1Djm5KZy/cJc5uamMHdyKlkpcYM/mK8bDr0XFNjecdYmA2cGxbzFcOHnIH8Z5JWc+uLKIiISdgpwIiIiI6Te0xmYBbJn3FoTVY3tvcfz0uOZOzmVm0vymZubypzJKWQmxQ79gG0NULXeCWv733a6Rvasp5Wa70wWkn+OMzYte65a1URExgB9kouIyKhW7+nkQGM7fmvx+y1+6yxGba3FZ51tZ7/FFzjut33bNrDdc9sXOBb8WD3l+z22n6D9zrYd5Dn81lLb3MnW6iZqmjp6612YkcCC/DQ+tKyQeYGwlp54nPWvrHUWQz7wNuxf57SuHdnlHDNupxvk4o87YS1/GaTmntkfvIiIhIUCnIiIjCrWWrYdbOalnXW8tLOOLVVHCed8XMaAyxjcxmAMuF0GlzG4DLhczv7UhGiWFE1wukDmpjJnciqp8dHHf+Dudqje2NcV8sDbfWunxaU5IW3+zU4r2+RFzjppIiIy5inAiYhIxPN0enmj7Agv76zj5V111LV0YgzMz0vjs5eexdzclN7g5HaZvlDlCgQp0/9YX8hyjvduB8o7YSzo/j2PbY597FNa5Pp4mmuCwto6qNkCfq9zLKMYZlwDBcuc4JZRrGn5RUTGKQU4ERGJSBVHWnkpENjeLm+gy+cnOTaKi86ayCUzs1g+Y+Lxx4dFMp8X6rb3nx3y6H7nWFQc5C6G8z4TmGxkKSRmhLe+IiISMRTgREQkInR5/ayvaHBC2846yo+0AjBtYiIfO6+QS2ZmsaRoAtHuUdjy1NEUmGzkHWf8WvUG6PI4x5ImOS1ry+50JhyZNA+ijjMWTkRExjUFOBERCZu6lg5e2XWYl3fW8XrZETydXmLcLs6ZlsFHzy1kxcxsCjIShn4AbydUvgkN+8Dvc9Y383uDbvdcvEHH/P3L+b1g/QPuFyjX736+/uV6j/lOfL+OJsA6C2Rnz4EFtzqta/lLIa3AGUgnIiJyEhTgRERkxPj9lveqm3q7Rr5b1QRAdkos1y7I4ZIZWZw/PZPE2OP8eTq6H8rWOpd9r0J329BlexiXM1OjKwpcbudiAteuqKDbg2z3u1+U08XxVO+XkOmEtbwSiE0epp+miIiMRwpwIiJyRrV0dPNG2ZFAaDvMEY8zAcnC/DQ+f/lZrJiVxeyclKEnA/F2OZN69IS2wzuc/WkFsPBDUHyF0+3QHe0EteCw1ROo1MIlIiJjhAKciIgMu/LDnt5p/tdXNNDts6TEOROQrJiZxcVnTSTjeBOQNNfAnrVQ9gLsfQW6WsAVDUXnw9kfgemXQ2axgpmIiIw7CnAiIhKyTq+Pd/b1TUBSUe90ayzOSuL286ewYmYWiwvTiRpqAhKf15nko+wFp5Wt9j1nf0ouzLvRaWWbcpG6H4qIyLinACciIqeltrmDlwOtbG/uOUJrl4+YKBfnTcvg9gumcMmMLPInHGcCEk8d7HnRCWx7/+5M9GHcUHAuXPYtJ7RlzVIrm4iISBAFOBEROSl+v2VL1VEntO2qY2t1MwA5qXGsXJTLihlZnDc9g4SYIf60+H1wcFOgle0F5zZAUjbMutbpFjntEohLHaFXJCIiMvoowImIyKCstVQfbWdDZSOv7j7Mq7sOU9/ahcvA2QXpfPHKGayYmcXMSclDT0DS1gB7/u4Etj0vQnuDM9FI3hJY8VWnlS17HrhG4dpuIiIiYaAAJyIiAPj8lh01zWyobGR9RQMbKhupaeoAIDU+mouDJiBJTxxioWm/Hw69G5gx8gWoLnXWTkvIcMJa8eUwbQUkTBjBVyYiIjJ2KMCJiIxTrZ1eNh84SmlFI6WVDWzafxRPpxeASSlxlBSlU1KYTknRBGZOSh56ApL2o1D+ct80/611gIHcs+Gi/3CC2+RFamUTEREZBiEFOGPMVcADgBtYba29b5AyNwPfBCywxVp7WyjPKSIip6e2uaM3rJVWNLK9phmf32IMzMhO5vpFk1lSNIHFhenkpsUP3S3SWqjd1tctcv86sD6IS4PplzqBbdqlkDRxZF+giIjIOHDaAc4Y4wYeBC4HqoD1xpg11trtQWWKgS8D51trG40xWaFWWERETszvt+w57HG6QlY0sr6ygQMN7QDERbtYkJfGpy+exuKidM4uSCc1Pvr4D9jZAuWv9k3z33LQ2T9pPlzw705oy10MbnXsEBEROZNC+Uu7FNhjrS0HMMY8DqwEtgeV+WfgQWttI4C1ti6E5xMRkSF0dPt4t6qpt3VtQ2UjTe3dAGQmxbC4MJ2PnVvE4sJ05kxOJSbqON0ZrYWGcmeWyOoNUL3RufZ3Q0yyM1Nk8RUw/TJIyRmhVygiIiIQWoDLBQ4EbVcBywaUOQvAGPMmTjfLb1prnxvswYwxdwB3ABQUFIRQLRGRsa/e08mGykZKKxsprWhga3UzXT4/ANMmJnLVnEmUFKWzpGgChRkJQ3eHBGiugYMb+8LawU3QcdQ5FhUHOQvg3H91Qlv+MnCfoLVOREREzphQAtxg3wbsII9fDCwH8oDXjTFzrbVHj7mjtauAVQAlJSUDH0dEZNyy1lJR38b6igZKKxoorWyk/HArADFuF/PyUvnE+UWUBMavTRhqhkiA9saglrVNTnBrqXGOGTdkz4bZK50JSCaf7SykrcAmIiISMUIJcFVAftB2HnBwkDLrrLXdwD5jzC6cQLc+hOcVERnTurx+th1s6jfhSH1rF+BM519SmM4HF+dTUpTOvNxU4qLdQzxQmzOlf08XyIMbna6RPTKmQ9GFfWFt0jyISRiBVygiIiKnK5QAtx4oNsZMAaqBW4CBM0z+FbgV+JUxJhOnS2U5IiLSy9Pp7Wtdq2hk84GjdHqd7pCFGQlcPGMiJYUTWFKUzrSJSbhcg3SA8HVD3fb+3SDrdjizQwKk5DpT+S/6sBPWJi+C+LQRfJUiIiIyHE47wFlrvcaYu4Hncca3PWKt3WaMuRcotdauCRy7whizHfABX7TW1g9HxUVERrsDDW088uY+nlx/gNYuH26XYe7kFD60rJAlReksLkwnKyXu2Dv6/dCwNyisbYRD74HXWXSb+HQnpM242rnOPRuSJ43sixMREZEzwlgbecPNSkpKbGlpabirISJyRmyobOThN8p5bushXMZw7YLJ3LQ4j0UFaSTEDPi/mrXQXN0/rB3cDJ3NzvHoBMhZGOgGuci5Tp8Cx5u0RERERCKeMWaDtbZk4H4t2CMiMgK8Pj8vbK/ll6+Xs2n/UVLioviXi6fxsXOLmJQa1MrWWh+YEXJj33VrYAUWVxRkz4V5N/W1rGXO0NprIiIi44j+6ouInEEtHd08WVrFo2/uo6qxncKMBL513RxuWpxHYmwUdHpgw6+g/BUnrB2tDNzTQOZZMP3SvrCWPReiB+lSKSIiIuOGApyIyBlQfbSdX725j8ffOUBLp5elRRP42vtnc9msbNwuA4d3wfqHYcvvne6QKXmQtxhKbnfCWs5CiEsJ98sQERGRCKMAJyIyjLYcOMrqN/bxzHvO2mrXzMvhkxdMYWF+mjNT5M41sH417HsN3DEw+3pY+s+Qt0Tj1kREROSEFOBERELk81te3FHL6tfLWV/RSHJsFLefX8THz59Cblo8tByCV+6HDY86i2an5sOlX4dFH4WkieGuvoiIiIwiCnAiIqeptdPLHzdU8cib+6isbyM3LZ6vvX82N5fkkRwbBZVvwtrVsOMp8Hth2qXw/h9C8RXgGmLxbREREZHjUIATETlFh5o6+PU/Knjs7f00tXezMD+N/7hyJlfOySaq2wPv/soZ33Z4B8SlwbI7nbFtGdPCXXUREREZ5RTgRERO0tbqJh5+Yx9PbTmI31qumjuJT14wlcWF6VC3A577Pmx5HLo8ziQkKx+EOTdATEK4qy4iIiJjhAKciMhx+P2Wl3fV8cvXy1lX3kBijJuPnFvIJ86bQkFatNM98tGHofINcMfC3BtgyT87M0lqUhIREREZZgpwIiKDaO/y8aeNVTzyxj7Kj7SSkxrHV66ZyT8tKSC1+zBs+JGzfpunFtIK4fJ7YeGHITEj3FUXERGRMUwBTkQkSF1LB7/9RyX/b10ljW3dzMtN5YFbFnLN3ElE738D1nwTdj4N1u9MRrLkU85i25qUREREREaAApyICLCjppmH39jHms0H6fb7uWxWNv984VSWTHJh3n0CHloNR3ZDfDqce5czKcmEKeGutoiIiIwzCnAiMm5Za3l192FWv76PN/YcIT7azS1L8/nE+VOY4t0H6++Fx56E7lbIXQzXPwRzrofo+HBXXURERMYpBTgRGXc6un38dVM1D7+xj7I6D9kpsfzHVTO4bfEk0iqeg799Hg6sg6g4mHsTLPmkMymJiIiISJgpwInIuHHE08n/W1fJb/9RSX1rF7NyUvjBzQt4f6GPmM2/gYd+Da2HIX0KXPF/YeFtkDAh3NUWERER6aUAJyJj3p46D6tfL+fPm6rp8vpZMTOLT51fyLlmK6b0S/DUM2AtnHUVLP0UTF0BLle4qy0iIiJyDAU4ERmz9h1p5YEXd/O3LQeJcbu4aXEen1qcztTqNfDcnVC/BxIy4fzPwuKPQ3phuKssIiIiclwhBThjzFXAA4AbWG2tvW/A8Y8D3wOqA7t+aq1dHcpzioicyIGGNn789zL+vKmaaLfhjoum8umzWknbtgp+8wfwtkPeUrjhlzB7JUTFhrvKIiIiIifltAOcMcYNPAhcDlQB640xa6y12wcUfcJae3cIdRQROSkHj7bzk5f28IfSA7hcho+dU8g9U/aTtv7f4e1/QHQCzL/ZmZQkZ0G4qysiIiJyykJpgVsK7LHWlgMYYx4HVgIDA5yIyBlV19zBz17Zy2Nv78diuXVJPp8rLCe99G7YuBFS8uDK7ziTksSnhbu6IiIiIqctlACXCxwI2q4Clg1S7kZjzEXAbuDfrbUHBimDMeYO4A6AgoKCEKolIuNFvaeTh17dy2/+UYnXb/ngosl8oaiMzA3/ClvehbRCuPYBWHAbRMWEu7oiIiIiIQslwJlB9tkB208Bv7fWdhpj7gR+DawY7MGstauAVQAlJSUDH0dEpNfRti5WvVbOr96qoKPbxwcWTuJLBbvI2vRt2LYdJkyD638O8z4I7uhwV1dERERk2IQS4KqA/KDtPOBgcAFrbX3Q5i+B+0N4PhEZ55o7unn49X088sY+PF1erpuXxVfyt5G9+RuwowwyZ8ANq2HuDeByh7u6IiIiIsMulAC3Hig2xkzBmWXyFuC24ALGmBxrbU1g8zpgRwjPJyLjVGunl1+9VcGq18ppau/m6tkZfL3gXXK2/Cfs3gfZc+GDv4JZK7V+m4iIiIxppx3grLVeY8zdwPM4ywg8Yq3dZoy5Fyi11q4B7jHGXAd4gQbg48NQZxEZJ9q7fPx2XQUPvVpOQ2sXV8xI4xt5m8jd+n+gfD/kLIRbHoOzrlZwExERkXHBWBt5w81KSkpsaWlpuKshImHS0e3j9+/s52ev7OVwSycrpiXzrfwN5G9bBS0HIW8JXPQfUHw5mMGG44qIiIiMbsaYDdbakoH7Q1rIW0RkOHV5/TxZeoAHX95DTVMHFxUm8KcF2yjYuRqqa6HgPLj+ZzB1uYKbiIiIjEsKcCISdl6fnz9vrObHL5VR1djOeXkx/H7WJgp3P4IprYcpF8NNj0DRBeGuqoiIiEhYKcCJSNj4/JY1W6p54MUyKurbOHeym99Mf5spe36D2dwI0y9zukoWDLbEpIiIiMj4owAnIiPO77c8u/UQP3xxN3vqPCzJsjy86A2mlv8O816zMynJxV+E3MXhrqqIiIhIRFGAE5ERY63lhe21/HDtbnYeaqEk08uL819nWsXvMTs8MOs6uOiLkDM/3FUVERERiUgKcCJyxllreWXXYX6wdjfvVTexeEInL855hWmVT2J2dzgLb1/4BcieHe6qioiIiEQ0BTgROWOstby5p54frN3Fxv1HWZTWytqZLzP9wJ8w5V6YfzNc+HnILA53VUVERERGBQU4ETkj3tnXwP+8sIu39zWwKKWZtcV/Z/rBv2H2+2HBrXDh52DC1HBXU0RERGRUUYATkWG1aX8jP1i7m9fLjrAoqYEXpr5I8aH/xRx0waIPwwX/DmkF4a6miIiIyKikACciw2JrdRM/WLubl3bWcXbCYdYWvsD0umcxdTGw5FNw3j2QmhvuaoqIiIiMagpwIhKS/fVtfOfZHTy79RCL42pYm/880w+vxTTEwzn/6gS35OxwV1NERERkTFCAE5HT4un08uDLe3j49X3MdVeyNvc5iutfhqYkp5vkuXdBYma4qykiIiIypijAicgp8fstf95Uzf3P7WSCp4w/Zj7N/JbXwZMKF38Jlt0JCRPCXU0RERGRMUkBTkRO2obKRu59ahue6u38MGUNF8S+Dl0psPzLTnCLTwt3FUVERETGNAU4ETmhmqZ27n92J5u3bOBL8X/jqtjXwSY6i2+fe5da3ERERERGiAKciAypo9vHqtfKeeqVt7jT/IkfxL6Bccdizr0Hzvs3SMwIdxVFRERExhUFOBE5hrWWp9+r4ZGnX+em1t/zXNRrGHc0riV3wgWfhaSscFdRREREZFxSgBORfrZWN/GTv77G+TW/5omol3HHuHCVfBIu+Byk5IS7eiIiIiLjWkgBzhhzFfAA4AZWW2vvG6LcTcAfgCXW2tJQnlNEzozDLZ384um3mLz1IX4c9Xeioy2c/RFcF30BUvPCXT0RERERIYQAZ4xxAw8ClwNVwHpjzBpr7fYB5ZKBe4C3Q6moiJwZXV4/j7+yEd/rP+LzPE9slA/vvFtwrfgSpBeGu3oiIiIiEiSUFrilwB5rbTmAMeZxYCWwfUC5bwPfBb4QwnOJyDCz1vLa5l1UPfM9bux6injTTeuMG4i/4ivEZEwLd/VEREREZBChBLhc4EDQdhWwLLiAMWYRkG+t/V9jzHEDnDHmDuAOgIKCghCqJSInsnd/Fe/+8Ttc1vQnLjQdHC68hsRrv0nyxLPCXTUREREROY5QApwZZJ/tPWiMC/gh8PGTeTBr7SpgFUBJSYk9QXEROQ1HG+vZ+OR3WHzwMT5gWtmXfRlxH/gW2Tlzw101ERERETkJoQS4KiA/aDsPOBi0nQzMBV4xxgBMAtYYY67TRCYiI8vb3syWP3+faWUPswIP21MvhOu/xZSpi8NdNRERERE5BaEEuPVAsTFmClAN3ALc1nPQWtsEZPZsG2NeAb6g8CYygrraKH/uJ0zY9CCLbRObYpeS9r6vM3v+heGumYiIiIichtMOcNZarzHmbuB5nGUEHrHWbjPG3AuUWmvXDFclReQUdXdQ/9ovcL/1I6b6GnjHtQD/8i+z7KKrCLSIi4iIiMgoFNI6cNbaZ4BnBuz7+hBll4fyXCJyErxddLzzKF0vf4+M7sO8Y2dTveh+rn7fjcRFu8NdOxEREREJUUgBTkQihK8b/6bHaP/7d0hsr2Gr/yzWT/kKN9x4G0tT4sJdOxEREREZJgpwIqOZzwvvPUnH379DXMt+yvzT+Fv6t1l540f4dEF6uGsnIiIiIsNMAU5kNPL7YOuf6X75O0Q37qXMX8SjMV/homs+xNcX5Wqcm4iIiMgYzSzcAAAQ+0lEQVQYpQAnMpr4/bDjb/hf/g6uI7sotwU84P880y+4mf+6ZDoJMXpLi4iIiIxl+rYnMhpYCzufxr7y35jabVSaPL7XdQ+uOSv5yjWzyUtPCHcNRURERGQEKMCJRLq9L8OL34SazdS4c7mv6y72ZV/BV6+dx7KpGeGunYiIiIiMIAU4kUh1cJMT3MpfoSF6Ev/d/S+85lrB566fzQ9L8nG7NM5NREREZLxRgBOJNPV74aVvw7a/0OpO5Qfej/K493JuO286L15aTEpcdLhrKCIiIiJhogAnEilaauHV+7Ebf02XjWKV7wYe9b6f65bO5KXl08jWem4iIiIi454CnEi4dTTDWz/G/9ZPsd4uHvOt4CF7I1cuW8BzF08lS8FNRERERAIU4ETCxdsJ6x/G9+p3cXc08rTvHH7CLVy4bBl/uXgqWckKbiIiIiLSnwKcyEjz++DdJ+n++38R3VLFW/55/Mh+kbPPuYTfXTSNicmx4a6hiIiIiEQoBTiRkWItlL1A53NfI7ZhFzv8U/iR/U+mn3stD104VcFNRERERE5IAU5kJBx4h7ZnvkpCzdsc9GfzEz7LxHNu5rsXTSczScFNRERERE6OApzImXR4Fy1Pf43kiudptal8336S+HNu56sXn8WExJhw105ERERERhkFOJEzoamao8/eS8rOJ8HG8mN7M75ln+bu5XMV3ERERETktCnAiQyntgbqn7+f5HcfId7v57dcjWfJv/GRSxaRruAmIiIiIiFSgBMZDl1t1L74AEmlPyXd18pTXEjt4s9z82XnkZag4CYiIiIiwyOkAGeMuQp4AHADq6219w04fidwF+ADPMAd1trtoTynSETxeal+5ZckvPU9sn31vMrZVC76IiuvuJzUhOhw105ERERExpjTDnDGGDfwIHA5UAWsN8asGRDQHrPWPhQofx3wA+CqEOorEhmspfKNJ4h57b/I7T7AZs5i7bzvcOU1N3BxvIKbiIiIiJwZobTALQX2WGvLAYwxjwMrgd4AZ61tDiqfCNgQnk8kIuxd/xys/QbTunayl1yemvV9Lrr2YyxUV0kREREROcNCCXC5wIGg7Spg2cBCxpi7gM8BMcCKoR7MGHMHcAdAQUFBCNUSOTN2bX6Lzue/wfz2dzhEBi8Wf42lH7iLaxPiw101ERERERknQglwZpB9x7SwWWsfBB40xtwGfBX42GAPZq1dBawCKCkpUUudRIxt296l6Zlvco7nJVpMAm9OuYf5N3yRy5JTwl01ERERERlnQglwVUB+0HYecPA45R8Hfh7C84mMqHd37eHQU99mectT+I2LTQUfZcaNX+f8tMxwV01ERERExqlQAtx6oNgYMwWoBm4BbgsuYIwpttaWBTbfB5QhEuE27TlA+ZrvckXTH5hjOtk1eSWFN97L4kx17RURERGR8DrtAGet9Rpj7gaex1lG4BFr7TZjzL1AqbV2DXC3MeYyoBtoZIjukyKRoHTvIbY99WOuafwti0wz5VkrmPSB/8vsybPDXTUREREREQCMtZE33KykpMSWlpaGuxoyTqzfW8s7Tz/M+488SqGrjoNpi5mw8r+Jm3JOuKsmIiIiIuOUMWaDtbZk4P6QFvIWGc3Wb99D2bM/ZXnz37jLNFCfUkzH+37C5JlXghlsjh4RERERkfBSgJNxxVrL5g3rOPLSj7mg9UWWmC6qM5bReem/kTHranC5wl1FEREREZEhKcDJuGD9Pra/9me63/oZi7o20kEMlXnvo+iaz5ObOy/c1RMREREROSkKcDKm2c4W9qz9JQmbVjPHV00dE9g4/TPMvvYeZqRmhbt6IiIiIiKnRAFOxiTbWMmB5x8gY9fjFNtWtpliyuffx9L3fZys2PhwV09ERERE5LQowMnYYS228i0Ov/gAGVVrmWzhFfd5eJf9C5dc9j5io9zhrqGIiIiISEgU4GT083Zit/6Jlld/SkrjNmJsIo9FX0/KhZ/m6vNLiInSxCQiIiIiMjYowMno5anDrn+YrnWrie08Qq0/l1/EfZqpK27nliXTiXYruImIiIjI2KIAJ6NPzbvYdT/HvvcHXP5u3vQt5OnEuznn0hv57Nl5Cm4iIiIiMmYpwMno4PfBrmex636GqXyTDuJ40rucv6dcz8pLl3P/wslEKbiJiIiIyBinACeRraMJNv4W+84qzNFKak0Wq7s/xNvp13D7pQt5ZL6Cm4iIiIiMHwpwEpnq98Lbv8Bu/h2my8N77tk82PVZyidcxN0rZ/Ll+ZNxu0y4aykiIiIiMqIU4CRyWAv7XoV1P8fufh5r3LzovpAHOi+jO2sen7mumGvm5Si4iYiIiMi4pQAn4dfdDu8+CW8/BHXb6YjJ4Inof+KnLRcxITufe64r5uq5k3ApuImIiIjIOKcAJ+HTfBDWr4bSR6G9gcaUmTwUcw+PNi9m6qQJ3HtdMVfOUXATEREREemhACcjr2oDrPsZbP8r1u+jOnsF9/tX8FRdEXMmp/KTlcVcPitbwU1EREREZAAFOBkZvm7YsQbW/Ryq1mNjk9lVeBtfrzmPdypTmJubwi9XnsVls7IwRsFNRERERGQwCnDSx1pnPFp3O3S3Ba5b+7a72oKOtQWVaYeu1gHHBtynowm6WrDpUymd/WW+snceZTtgfl4qD68sZsVMBTcRERERkRMJKcAZY64CHgDcwGpr7X0Djn8O+BTgBQ4Dt1trK0N5zrDoaoW9L4W7FsdnLXg7TyNwDQhpp8q4ISYRouMhOiFwiYeYBIjLCexPxBcVz6v++Xxtaw7VG7tYmJ/GozcUs/ysiQpuIiIiIiIn6bQDnDHGDTwIXA5UAeuNMWustduDim0CSqy1bcaYTwPfBf4plAqHRetheOLD4a7FqTOu/qEqOsEJVtEJkJTVG66c6/jBg1h0At3ueNptDG02Bo8/Bo+NocUbTZMvipZuF54OL55O59La6aUlcO1p6tvf2NpFa5ePswsS+O+bFnJRcaaCm4iIiIjIKQqlBW4psMdaWw5gjHkcWAn0Bjhr7ctB5dcBozAFAck5cOcb4a7FiUXF94axbnc8rV4XLZ2+Y4PVgMDl6fTiafHh6egO7Pfh6eymtdOHp8NLl68NOHHrXEKMm6TYKOcSF0ViTBT5ExJIio0iOS6Ky2dnc8F0BTcRERERkdMVSoDLBQ4EbVcBy45T/pPAs0MdNMbcAdwBUFBQEEK1ht+hVssnnjga7mocl7WW9u4jveGs0+s/qfvFR7tJiovqDV6JsW5y0+JJik1yQlhsFMmxznVwOOsX1GKdsKYFtkVEREREzqxQAtxg39btoAWN+TBQAlw81INZa1cBqwBKSkoGfZxwcbsMeenx4a7GCfVrAesJXXGDBy8ndLmJcrvCXW0RERERETlJoQS4KiA/aDsPODiwkDHmMuA/gYuttZ0hPF/YTEyO5ZcfLQl3NUREREREZJwLpfllPVBsjJlijIkBbgHWBBcwxiwCfgFcZ62tC+G5RERERERExr3TDnDWWi9wN/A8sAN40lq7zRhzrzHmukCx7wFJwB+MMZuNMWuGeDgRERERERE5gZDWgbPWPgM8M2Df14NuXxbK44uIiIiIiEgfzWAhIiIiIiIySijAiYiIiIiIjBIKcCIiIiIiIqOEsTaillwDwBhzGKgMdz0GkQkcCXclpJfOR2TR+YgsOh+RRecjsuh8RBadj8ii8xE5Cq21EwfujMgAF6mMMaXWWi0IFyF0PiKLzkdk0fmILDofkUXnI7LofEQWnY/Ipy6UIiIiIiIio4QCnIiIiIiIyCihAHdqVoW7AtKPzkdk0fmILDofkUXnI7LofEQWnY/IovMR4TQGTkREREREZJRQC5yIiIiIiMgooQAnIiIiIiIySijADWCMucoYs8sYs8cY838GOR5rjHkicPxtY0zRyNdyfDDG5BtjXjbG7DDGbDPG/NsgZZYbY5qMMZsDl6+Ho67jiTGmwhjzXuDnXTrIcWOM+XHgPfKuMebscNRzPDDGzAj63d9sjGk2xnx2QBm9R84gY8wjxpg6Y8zWoH0TjDFrjTFlgev0Ie77sUCZMmPMx0au1mPXEOfje8aYnYHPo78YY9KGuO9xP9vk1A1xPr5pjKkO+ky6Zoj7Hvf7mJy6Ic7HE0HnosIYs3mI++r9EUE0Bi6IMcYN7AYuB6qA9cCt1trtQWX+FZhvrb3TGHML8AFr7T+FpcJjnDEmB8ix1m40xiQDG4DrB5yP5cAXrLXvD1M1xx1jTAVQYq0ddJHPwB/jzwDXAMuAB6y1y0auhuNT4POrGlhmra0M2r8cvUfOGGPMRYAH+I21dm5g33eBBmvtfYEvnunW2i8NuN8EoBQoASzO59tia23jiL6AMWaI83EF8JK11muMuR9g4PkIlKvgOJ9tcuqGOB/fBDzW2u8f534n/D4mp26w8zHg+P8ATdbaewc5VoHeHxFDLXD9LQX2WGvLrbVdwOPAygFlVgK/Dtz+I3CpMcaMYB3HDWttjbV2Y+B2C7ADyA1vreQkrMT542CtteuAtEAYlzPrUmBvcHiTM89a+xrQMGB38N+JXwPXD3LXK4G11tqGQGhbC1x1xio6Tgx2Pqy1L1hrvYHNdUDeiFdsnBri/XEyTub7mJyi452PwHfZm4Hfj2il5LQowPWXCxwI2q7i2MDQWybwB6EJyBiR2o1jga6qi4C3Bzl8rjFmizHmWWPMnBGt2PhkgReMMRuMMXcMcvxk3kcy/G5h6D+8eo+MrGxrbQ04/4gCsgYpo/dJeNwOPDvEsRN9tsnwuTvQpfWRIboY6/0x8i4Eaq21ZUMc1/sjgijA9TdYS9rAPqYnU0aGkTEmCfgT8FlrbfOAwxuBQmvtAuAnwF9Hun7j0PnW2rOBq4G7Al0yguk9MsKMMTHAdcAfBjms90hk0vtkhBlj/hPwAr8bosiJPttkePwcmAYsBGqA/xmkjN4fI+9Wjt/6pvdHBFGA668KyA/azgMODlXGGBMFpHJ63QPkJBhjonHC2++stX8eeNxa22yt9QRuPwNEG2MyR7ia44q19mDgug74C05Xl2An8z6S4XU1sNFaWzvwgN4jYVHb0204cF03SBm9T0ZQYJKY9wMfskMM/j+JzzYZBtbaWmutz1rrB37J4D9nvT9GUOD77A3AE0OV0fsjsijA9bceKDbGTAn8R/sWYM2AMmuAntnCbsIZGK3/Cp0Bgf7YDwM7rLU/GKLMpJ4xiMaYpTi/0/UjV8vxxRiTGJhQBmNMInAFsHVAsTXAR43jHJwB0TUjXNXxZsj/nOo9EhbBfyc+BvxtkDLPA1cYY9IDXciuCOyTYWaMuQr4EnCdtbZtiDIn89kmw2DAmOgPMPjP+WS+j8nwuQzYaa2tGuyg3h+RJyrcFYgkgRmq7sb5I+oGHrHWbjPG3AuUWmvX4ASK3xpj9uC0vN0SvhqPeecDHwHeC5rW9itAAYC19iGcEP1pY4wXaAduUaA+o7KBvwTyQBTwmLX2OWPMndB7Tp7BmYFyD9AGfCJMdR0XjDEJODO1/UvQvuDzoffIGWSM+T2wHMg0xlQB3wDuA540xnwS2A98MFC2BLjTWvspa22DMebbOF9UAe611qo3R4iGOB9fBmKBtYHPrnWBmaQnA6uttdcwxGdbGF7CmDLE+VhujFmI0yWygsBnV/D5GOr7WBhewpgy2Pmw1j7MIGOo9f6IbFpGQEREREREZJRQF0oREREREZFRQgFORERERERklFCAExERERERGSUU4EREREREREYJBTgREREREZFRQgFORERERERklFCAExERERERGSX+PwCtRqZFp2ZpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.666000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
